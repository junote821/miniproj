import os, asyncio
from typing import Optional, List, Dict
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv(), override=False)

from google.adk.agents import LlmAgent
from google.adk.runners import InMemoryRunner
from google.genai import types
from google.adk.models.lite_llm import LiteLlm

MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-4o-mini")

ragqa_agent = LlmAgent(
    name="ragqa_agent",
    model=LiteLlm(model=MODEL_NAME) if "/" in MODEL_NAME else MODEL_NAME,
    instruction=(
        "ì—­í• : ë¦¬ì„œì¹˜ ë¶„ì„ê°€.\n"
        "ê·œì¹™:\n"
        "- ì£¼ì–´ì§„ 'ê·¼ê±° ì»¨í…ìŠ¤íŠ¸'ë§Œìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µí•˜ë¼.\n"
        "- ë¬¸ì¥ ëì— ìµœëŒ€ 3ê°œì˜ ê·¼ê±°ë¥¼ [refN:ì œëª©|ì¶œì²˜] í˜•ì‹ìœ¼ë¡œ ì¸ìš©í•œë‹¤.\n"
        "- í™•ì‹¤ì¹˜ ì•Šì€ ìˆ˜ì¹˜ëŠ” 'ì¶”ì •ì¹˜'ë¡œ í‘œê¸°í•œë‹¤.\n"
        "- ë§ˆì§€ë§‰ì— 'í•œê³„ì™€ ë‹¤ìŒ ì•¡ì…˜'ì„ 2ì¤„ ì´ë‚´ë¡œ ì œì‹œí•œë‹¤.\n"
    ),
)

async def _run_once(agent: LlmAgent, sys_prompt: str, user_prompt: str) -> str:
    runner = InMemoryRunner(agent=agent, app_name=agent.name)
    try:
        await runner.session_service.create_session(app_name=agent.name, user_id="u", session_id="s")
    except Exception:
        pass
    final = ""
    async for ev in runner.run_async(
        user_id="u", session_id="s",
        new_message=types.Content(role="user", parts=[types.Part(text=f"{sys_prompt}\n\n{user_prompt}")]),
    ):
        if ev.is_final_response() and ev.content and ev.content.parts:
            final = ev.content.parts[0].text or ""
    return final.strip()

def _format_refs(chunks: List[Dict], k_refs: int = 3) -> str:
    refs = []
    for i, c in enumerate(chunks[:k_refs], 1):
        title = c.get("title") or c.get("source", "")[:40]
        src = c.get("source", "")
        refs.append(f"[ref{i}:{title}|{src}]")
    return " ".join(refs)

def answer_with_context(question: str, chunks: List[Dict], k_refs: int = 3) -> str:
    # ì»¨í…ìŠ¤íŠ¸(ìƒìœ„ k_refsë§Œ ë³¸ë¬¸ í¬í•¨)
    ctx_lines = []
    for i, c in enumerate(chunks[:k_refs], 1):
        title = c.get("title") or c.get("source", "")
        ctx_lines.append(f"[{i}] {title}\n{c['text']}\n")
    context = "\n".join(ctx_lines) if ctx_lines else "(no context)"
    sys_p = (
        "ë‹¤ìŒì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ë‹¤. ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•´ ë‹µí•˜ê³ , ë¬¸ì¥ ëì— ì¸ìš©ì„ ë§ë¶™ì—¬ë¼.\n"
        f"{context}\n"
    )
    user_p = (
        f"ì§ˆë¬¸: {question}\n"
        "ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: í•µì‹¬ ë‹µë³€ ë¬¸ì¥ ... [ref1:ì œëª©|ì¶œì²˜] [ref2:ì œëª©|ì¶œì²˜]\n"
        "ë§ˆì§€ë§‰ ì¤„ì— 'í•œê³„ì™€ ë‹¤ìŒ ì•¡ì…˜: ...'ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
    )
    body = asyncio.run(_run_once(ragqa_agent, sys_p, user_p))
    # ì•ˆì „ë§: ì¸ìš©ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ ìµœì†Œ 1ê°œëŠ” ë¶™ì—¬ì¤Œ
    if "[ref" not in body:
        body = body.strip() + " " + _format_refs(chunks, k_refs=k_refs)
    return body

def answer_with_context(question: str, chunks: List[Dict], k_refs: int = 3) -> str:
    # (ê¸°ì¡´ í•¨ìˆ˜ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš” â€” ë°°ì¹˜/í…ŒìŠ¤íŠ¸ìš©)
    ctx_lines = []
    for i, c in enumerate(chunks[:k_refs], 1):
        title = c.get("title") or c.get("source", "")
        ctx_lines.append(f"[{i}] {title}\n{c['text']}\n")
    context = "\n".join(ctx_lines) if ctx_lines else "(no context)"
    sys_p = (
        "ë‹¤ìŒì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ë‹¤. ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•´ ë‹µí•˜ê³ , ë¬¸ì¥ ëì— ì¸ìš©ì„ ë§ë¶™ì—¬ë¼.\n"
        f"{context}\n"
    )
    user_p = (
        f"ì§ˆë¬¸: {question}\n"
        "ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: í•µì‹¬ ë‹µë³€ ë¬¸ì¥ ... [ref1:ì œëª©|ì¶œì²˜] [ref2:ì œëª©|ì¶œì²˜]\n"
        "ë§ˆì§€ë§‰ ì¤„ì— 'í•œê³„ì™€ ë‹¤ìŒ ì•¡ì…˜: ...'ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
    )
    body = asyncio.run(_run_once(ragqa_agent, sys_p, user_p))
    if "[ref" not in body:
        body = body.strip() + " " + _format_refs(chunks, k_refs=k_refs)
    return body

# ì¶”ê°€: ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ (ì½˜ì†”ì— ë°”ë¡œë°”ë¡œ ì¶œë ¥)
async def _run_once_stream(agent: LlmAgent, sys_prompt: str, user_prompt: str):
    runner = InMemoryRunner(agent=agent, app_name=agent.name)
    try:
        await runner.session_service.create_session(app_name=agent.name, user_id="u", session_id="s")
    except Exception:
        pass
    accumulated = ""
    async for ev in runner.run_async(
        user_id="u", session_id="s",
        new_message=types.Content(role="user", parts=[types.Part(text=f"{sys_prompt}\n\n{user_prompt}")]),
    ):
        # ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ delta í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œ ë°”ë¡œ ì¶œë ¥
        # (SDK ë²„ì „ì— ë”°ë¼ ì†ì„±ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ try/except)
        try:
            if hasattr(ev, "delta") and ev.delta and ev.delta.parts and ev.delta.parts[0].text:
                chunk = ev.delta.parts[0].text
                accumulated += chunk
                print(chunk, end="", flush=True)  # ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
        except Exception:
            pass

        if ev.is_final_response() and ev.content and ev.content.parts:
            final_text = ev.content.parts[0].text or ""
            # ìµœì¢… ë³¸ë¬¸ì´ ëˆ„ì ë³´ë‹¤ ê¸´ ê²½ìš° ë³´ì •
            if len(final_text) > len(accumulated):
                print(final_text[len(accumulated):], end="", flush=True)
            print()  # ì¤„ë°”ê¿ˆ
            return final_text.strip()
    return accumulated.strip()

def answer_with_context_stream(question: str, chunks: List[Dict], k_refs: int = 3) -> str:
    ctx_lines = []
    for i, c in enumerate(chunks[:k_refs], 1):
        title = c.get("title") or c.get("source", "")
        ctx_lines.append(f"[{i}] {title}\n{c['text']}\n")
    context = "\n".join(ctx_lines) if ctx_lines else "(no context)"
    sys_p = (
        "ë‹¤ìŒì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ë‹¤. ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•´ ë‹µí•˜ê³ , ë¬¸ì¥ ëì— ì¸ìš©ì„ ë§ë¶™ì—¬ë¼.\n"
        f"{context}\n"
    )
    user_p = (
        f"ì§ˆë¬¸: {question}\n"
        "ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: í•µì‹¬ ë‹µë³€ ë¬¸ì¥ ... [ref1:ì œëª©|ì¶œì²˜] [ref2:ì œëª©|ì¶œì²˜]\n"
        "ë§ˆì§€ë§‰ ì¤„ì— 'í•œê³„ì™€ ë‹¤ìŒ ì•¡ì…˜: ...'ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
    )
    # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
    return asyncio.run(_run_once_stream(ragqa_agent, sys_p, user_p))
