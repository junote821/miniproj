{"id": "d1a024a2fcb3fb46c2d8b13151251795", "text": "Tech Legal Insights\n2025. 07AID (Artificial Intelligence Decoding) V ol. 6\nRelated Areas\nAI 의료기기\n의료보험시장\nContact\n구태언 변호사\nT.  02-3477-8695\nE. tekoo@law -lin.com식약처는 2025년5월7일자로 ‘인공지능기술이 적용된 디지털의료기기의 허가·심사가\n이드라인 ’을제정하였습니다 .이미2022년5월에‘인공지능 의료기기의 허가·심사가이드\n라인’이나왔지만 2025년부터 디지털의료제품법이 의료기기법의 특별법으로 시행되고\n있기때문에 그에맞춰기술변화 등을반영,새롭게 제정된 것입니다 .법적구속력이 없는\n문서이지만 의료기기의 허가·심사부처인 식약처는 인공지능 기반의 디지털의료기기 시\n장이발전하고 있는추세에 맞춰 2025년1월,‘생성형 인공지능 의료기기 허가·심사가이\n드라인 ’을세계최초로 만들정도로 우리의 디지털의료환경이 글로벌시장에서 앞서나가\n고있음을 보여주고 있습니다 .\n이하에서는 AI의료기기를 둘러싼 주요현안이슈들을 살펴보고 관련의료보험시장의 변\n화또한소개합니다 .\n1.AI의료기기와 법적쟁점들\n1-1.정의문제\n가.2025년5월의식약처 ‘인공지능기술이 적용된 디지털의료기기의 허가·심사가이드라\n인’은2022년5월에식약처가 ‘인공지능 의료기기의 허가·심사가이드라인 ’에서정의한\n‘기계학습 가능의료기기 ’(Machine Learning -enabled Medical devices ;이하‘MLMD’) 개념\n을그대로 사용,기계학습 방식으로 의료용 데이터를 학습하고 특정패턴을 인식하여 질\n병을진단예측하거나 환자에게 적합한 ", "source": "data/raw/Tech Legal Insights.pdf", "page": 1, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "0a8a74d771c28fe231132b2611999c40", "text": "abled Medical devices ;이하‘MLMD’) 개념\n을그대로 사용,기계학습 방식으로 의료용 데이터를 학습하고 특정패턴을 인식하여 질\n병을진단예측하거나 환자에게 적합한 맞춤치료법을 제공하는 기기를 대상으로 해당\n가이드라인이 적용됨을 밝히고 있습니다 .방석호 미국변호사\nT.  02-3477-8695\nE. shbang@law -lin.com\n설기석 변호사\nT.  02-3477-8695\nE. ksseol@law -lin.comAI의료기기를 둘러싼주요쟁점과보험시장의 변화\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.AID Vol. 6\n2현행디지털의료제품법은 지능정보기술 ,로봇기술 ,정보통신기술 등총리령으로 정하는 첨단기술이\n적용된 의료기기법상의 의료기기로 ‘디지털의료기기 ’를정의하는 기술기반 방식을 택함에 따라MLMD\n는기존의 의료영상 분석·검출또는진단보조에 사용하는 의료용 소프트웨어와는 다르며 또한기계학\n습기술을 활용하는 소프트웨어가 법상디지털의료기기에 해당되는 지의여부는 사용목적 ,기능및사\n용시인체에 미치는 잠재적 위해성 (危害性 )등의차이에 따라판단된다고 설명하고 있습니다 .\n즉소프트웨어 만으로도 디지털의료제품법상의 디지털의료기기로 분류,식약처의 허가·심사를 받아\n야만하는경우가 있음을 전제로 1)의료용 데이터를 기반으로 의료영상 ,체외진단기기로부터 나온,신\n호획득시스템 (심전계 ,", "source": "data/raw/Tech Legal Insights.pdf", "page": 2, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "2bcdc51876b4702a9e30174d3d5b14e9", "text": "료제품법상의 디지털의료기기로 분류,식약처의 허가·심사를 받아\n야만하는경우가 있음을 전제로 1)의료용 데이터를 기반으로 의료영상 ,체외진단기기로부터 나온,신\n호획득시스템 (심전계 ,뇌파계 등)에서나오는 패턴또는신호를 분석하여 질병의 진단·치료·예후관찰\n에필요한 임상정보를 제공하는 소프트웨어 ,2)의료용 데이터를 기반으로 의료정보를 분석하여 얻은\n임상정보(예:종양병변크기·위치등)를이용하여 환자의 질병유무,상태등에대한가능성 정도를 자\n동으로 진단·예측,모니터링하거나 치료하는 소프트웨어는 그런디지털의료기기가 될수있음을 예시\n하고있습니다 .\n나.식약처의 이러한 가이드라인 입장은 미국식품의약국 (FDA)의2022년9월28일,임상의사결정 지원\n(Clinical Decision Support, CDS)소프트웨어에 대한최종가이드라인 내용에서도 똑같이 확인됩니다 .특\n히의료전문가 (HCP ;Healthcare Professionals) 가사용하는 비의료기기 (non-device) SW에대한판별기\n준을구체적으로 제시하고 있다는 점에서 우리실무에서도 참조가 될수있습니다 .\n구체적으로 1)의료영상,체외진단기기(IVD)의신호,또는신호획득시스템의 패턴이나 신호를 획득,\n처리또는분석할 목적이 아닐것,2)환자에 대한의료정보 또는기타의료정보를 표시,분석또는인쇄\n할목적일 것,3)질병이나 상태의 예방,진단또는치료에 관해 HCP에게권고를 지원하거나 제공할 목\n적일것,4)HCP가소프트웨어가 제시하는 권고의 근거를 독립적으로 검토할 수있도록 하여,HCP가개\n별환자에 대한임상진단이나 치료결정을 내릴때주로해당권고에 의존하도록 의도되지 않았을 것의\n4가지", "source": "data/raw/Tech Legal Insights.pdf", "page": 3, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "820491c9337111e8937d8e16101e2e57", "text": "HCP가소프트웨어가 제시하는 권고의 근거를 독립적으로 검토할 수있도록 하여,HCP가개\n별환자에 대한임상진단이나 치료결정을 내릴때주로해당권고에 의존하도록 의도되지 않았을 것의\n4가지기준을 ‘모두’충족하면 비로소 ‘비의료기기 SW’로판단되어 미국FDA의디지털의료기기 규제에\n서제외시키고 있습니다 .\n실무적으로 주목해야 할부분은 세번째와 네번째기준입니다 .즉세번째기준은 의료용 SW가특정하\n고단일한 결과나 지시를 제공하여 HCP의판단을 ‘대체‘하는것이아니라 ,권고(정보/옵션으로 정의됨 )\n를제공함으로써 HCP의판단을 ‘지원’해야하며,예측을 위해위험확률,위험점수또는환자가 특정상\n태의‘징후를 보일수있다’는제안을 제공하는 SW의경우특정결과를 제공하는 것으로 간주하여 세번\n째기준을 충족하지 못한다고 미국FDA는구체적으로 적시하고 있습니다 .또한네번째의 기준은 HCP\n가SW기반의 권고에 도달한 방법을 이해하고 자신의 판단을 적용할 수있을만큼충분히 투명해야 한\n다는것으로서 결국의료행위의 주체인 HCP로하여금 SW활용결과물에 ‘주로’의존하도록 해서는 안\n되며이기준을 충족하지 못하면 역으로 미국 FDA규제를 받는의료기기로 분류되어진다는 의미가 됩\n니다.\n이런입장은 AI의료기기가 의료행위의 주체인 의사를 보조하는 도구로 기능하여야만 한다는 의미이고\n우리의 현행의료법 체계는 물론글로벌 의료AI의기술수준도 반영한 결과물이라고 할수있습니다 .\n1-2.생성형인공지능 의료기기와 의사의설명의무\n가.식약처가 2025년1월발표한 ‘생성형 인공지능 의료기기 허가·심사가이드라인 ’은기존의 기계적 학\n습(machine learning) 기반의 AI모델과", "source": "data/raw/Tech Legal Insights.pdf", "page": 4, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "f7d6c1bea23eb54fd4c97af3b1883592", "text": " 의료기기와 의사의설명의무\n가.식약처가 2025년1월발표한 ‘생성형 인공지능 의료기기 허가·심사가이드라인 ’은기존의 기계적 학\n습(machine learning) 기반의 AI모델과 달리방대한 데이터의 패턴기반의 확률적 추론을 통해새로운 콘\n텐츠를 끊임없이 생성하기 때문에 기존방식으로 성능및임상적 유효성을 평가하는 데어려움이 있음\n을전제로 그러한 ‘생성형 인공지능 의료기기 ’에대한특성중하나로 ‘설명불가능성 (inexplicability) 을들\n고있습니다 .\n즉생성형의료기기 출력값에대한근거(rationale) 는잘훈련된 임상의와 기타의료진도 잘이해하지 못\n하는생성형 AI자체의 기술적 특성이라는 점을지적한 것입니다 .\n문제는 의료행위의 주체인 의료인은 의료법상 설명의무를 부담하고 있고전통적으로 의료과오소송\n(medical malpractice) 에서중요한 쟁점이라는 점입니다 .\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n3AID Vol. 6\n나.구체적으로 의료법 제24조의2는의료인이 환자에게 치료방법과 위험을 설명할 의무를 규정하고 있\n고대법원은 “환자가 인공지능을 활용한 의료행위에 응할것인지를 합리적으로 결정할 수있도록 의사\n의설명의무는 의료행위가 행해질 때까지 적절한 시간적 여유를 두고이행되어야 하며,환자에게 충분\n한숙고와 상의의 시간을 제공해야 한다”고상세하게 판결하고 있습니다 .(대법", "source": "data/raw/Tech Legal Insights.pdf", "page": 5, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "04cc2166e4d83bac1333cb0caa16f08e", "text": "있도록 의사\n의설명의무는 의료행위가 행해질 때까지 적절한 시간적 여유를 두고이행되어야 하며,환자에게 충분\n한숙고와 상의의 시간을 제공해야 한다”고상세하게 판결하고 있습니다 .(대법원 2022.1.27.선고2021\n다265010 판결)\n예를들어,폐질환 병변판독을 생성형 의료기기가 한뒤이를바탕으로 수술여부를 의사가 결정,설명\n의무를 이행한다고 할때의사는 의료법에 따라환자에게 ‘수술등의필요성 ,방법및내용’을설명하여야\n만하기때문에 논리적으로는 질병관련사항은 물론이고 생성형 의료기기의 역할,신뢰성과 한계등도\n설명하여야만 환자는 ‘충분한 숙고와 상의의 시간’을확보할 수있다는 결론이 되지만 정작AI기반진단\n이나치료과정은 알고리즘의 복잡성 등으로 인해의사가 현실적으로 이를완전히 이해하거나 설명하는\n것이힘들다는 점입니다 .\n다.의사의 설명의무는 불법행위법상 ‘주의의무 ’(duty ofcare)를구체화한 것이기 때문에 생성형 AI의료\n기기를 사용하여 수술필요성 여부를 최종판단한 의사는 의료행위 주체로서의 판단근거 ,AI의료기기\n의신뢰성 ,한계등을설명할 수있으면 (explainable) 족한것이지 AI의료기기의 판단근거에 대한설명까\n지할(interpretable) 필요는 없다고 해석됩니다 .\n즉AI의작동과정에 대한Black Box부분은 AI의료기기 사용에 따른신뢰성 ,한계등에대한기술적 쟁점\n일뿐의사의 법적설명의무와는 무관한 것으로 볼수있습니다 .\n1-3.의료기기법상의 ‘위험등급’체계와허가·심사\n가.의료기기는 EU,미국,우리나라 모두위험 (risk)기반의 차별적 규제를 통해제품사용을 통제하면서\n안전을 확보하는 대표적 영역이고 ,위", "source": "data/raw/Tech Legal Insights.pdf", "page": 6, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "c1286c793f592b68a7985e8d18de8876", "text": ".의료기기법상의 ‘위험등급’체계와허가·심사\n가.의료기기는 EU,미국,우리나라 모두위험 (risk)기반의 차별적 규제를 통해제품사용을 통제하면서\n안전을 확보하는 대표적 영역이고 ,위험(위해성 )분류기준은 EU와우리나라가 4단계,미국 FDA는3단\n계구분을 하는등구체적 차이를 보이고 있지만 ,대부분의 국가들이 의료기기에 대해서는 ‘위험기반의\n규제방식 ’(risk-based approach) 을공통으로 택하고 있습니다 .\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n4AID Vol. 6\n위험등급을 정하기 위한첫단추에 해당되는 것은의료기기의 ‘사용목적 ’(intended use)이지만 AI를\n활용하는 디지털의료기기는 그특성상 자율적으로 데이터의 학습,훈련을 하면서 진화하기 때문에 ‘사\n용목적 ’을통한위험등급관리체제가 과연유효한 지에대한의문이 제기될 수있습니다 .이런점을반\n영,식약처의 2025년‘인공지능기술이 적용된 디지털의료기기의 허가·심사가이드라인 ’은MLMD 의특\n성을반영하여 적용된 알고리즘 (기계학습 포함)에관해작성한 자료를 제출하여 허가·심사를 받도록\n하고있습니다 .\n나.AI디지털의료기기 제작업체는 시장에서의 제품경쟁력을 유지하기 위해데이터 학습에 따른버전\n업데이트를 필수적 사항으로 생각하게 되지만 미국FDA는‘Predetermined Change Control Plan(PCCP)’\n이라는", "source": "data/raw/Tech Legal Insights.pdf", "page": 7, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "7c38fc5a317fd4508f68f436ea16b9b7", "text": "경쟁력을 유지하기 위해데이터 학습에 따른버전\n업데이트를 필수적 사항으로 생각하게 되지만 미국FDA는‘Predetermined Change Control Plan(PCCP)’\n이라는 개념을 도입,사전에 허가받은변경범위내의변경만을 인정함으로써 제조업계와 변경허가\n여부를 둘러싸고 갈등을 빚고있습니다 .\n우리의 디지털의료제품법 제11조는“디지털의료기기의 안전성ㆍ유효성에 영향을 미치는 총리령으\n로정하는 중요한 사항이 변경된 경우에는 식품의약품안전처장에게 변경허가 또는변경인증을 받거\n나변경신고를 하도록 ”하고,경미한 사항인 경우에는 식약처장에게 보고하도록 하고있습니다 .\n구체적으로 식약처장은 고시를 통해1)디지털의료기기 소프트웨어에 대해서는 가.사용목적 또는\n이와관련된 핵심적인 성능,나.생체신호 ·의료영상과 같은분석대상이나 분석기법 등알고리즘 (분석\n방법),다.소프트웨어 개발언어또는운영환경 ,라.법제14조에따른전자적 침해행위로부터의 보호\n조치에 영향을 미치는 통신기능 등,마.사용사양서 또는사용자 인터페이스의 변경중총괄평가 (혹\n은이와동등이상의 평가)를수반하는 변경을 핵심적인 성능에 대한변경으로 보고있고,2)하드웨어\n의변경중성능또는전기·기계적 안전에 영향을 미치지 않는해당디지털의료기기의 외관,치수,버\n튼의형태및위치,손잡이 등의변경을 제외한 변경또한핵심적인 성능에 대한변경으로 폭넓게 열\n거함으로써 모두식약처장의 변경허가를 받는대상이 되도록 운영하고 있습니다 .\n즉디지털의료기기에 대해서는 소프트웨어는 물론이고 하드웨어 부분의 사후변경도 핵심적인 성능\n에대한변경으로 넓게추정,보수적으로 변경허가·심사시스템을 시행하고 있습니다 .", "source": "data/raw/Tech Legal Insights.pdf", "page": 8, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "e78025481184d8fbea64286ccd2802d1", "text": " 있습니다 .\n즉디지털의료기기에 대해서는 소프트웨어는 물론이고 하드웨어 부분의 사후변경도 핵심적인 성능\n에대한변경으로 넓게추정,보수적으로 변경허가·심사시스템을 시행하고 있습니다 .\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n5AID Vol. 6\n2.의료로봇과 AI\n의료서류를 정리,보고서를 작성하거나 영상을 합성,변화함으로써 진단의 정확도를 높이거나\n통계적으로 유사한 합성데이터를 생성해 임상시험 ,연구,환자건강개선 등을지원하거나 새로운\n화합물 구조를 생성하여 약물개발을 가속화하는 등가상공간에서의 AI가아니라 의료로봇에\n탑재되어 활용되어지고 있는AI는진단시 실시간 데이터 분석과 최적의 수술경로 등의의사결정 ,더\n나아가 수술시 작업보조 ,재활등에초점을 맞춰상용화로 발전시킨 것이기 때문에 특정작업,특화된\n데이터와 알고리즘 ,복잡한 작업순서 등의성격상 더고차원적인 기술개발 ,또한이에상응하는\n복잡한 규제가 따라오게 됩니다 .\n특히진단이나 검사가 아닌외과수술에 사용되는 물리적 로봇은 FDA가분류한 기술등급에 따르면\n현재대부분 (세계적으로 압도적 시장점유율을 보이고 있는daVinci시스템 포함)레벨1수준이며 (da\nVinci는의사가 조종간을 직접움직이면 로봇수술기가 이동작을 동시에 재현하는 마스터 -슬레이브\n방식)에그치고 있고관절수술 등의일부에서 활용되는 Mako 시스템의 경우의사가 로봇팔을\n작동시키", "source": "data/raw/Tech Legal Insights.pdf", "page": 9, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "1f88dab490030eb6c89b2868d2407ce3", "text": "는의사가 조종간을 직접움직이면 로봇수술기가 이동작을 동시에 재현하는 마스터 -슬레이브\n방식)에그치고 있고관절수술 등의일부에서 활용되는 Mako 시스템의 경우의사가 로봇팔을\n작동시키면 정해진 범위내의 수술을 로봇이 그대로 실행하는 식의레벨2기술단계에 이르고는\n있지만 결국의료현장에서의 수술로봇은 현재기술적으로 ,또법적으로 인간의사의 ‘보조적 도구’에\n머물고 있다고 평가할 수있습니다 .\n인간의 신체와 생명을 대상으로 한다는 의료의 특성상 AI를장착한 로봇이 질병의 진단,검사,\n환자의 재활등의영역을 벗어나 수술등의의료행위를 자율적으로 할수있도록 하기위해서는\n법적으로만 볼때향후현의료법체계는 물론이고 수술로봇에 법인격을 부여할 것인지의 근본적\n문제부터 검토가 필요하다고 할수있습니다 .\n3.의료보험 시장의변화\n3-1.AI가의료기기 ,데이터처리 등에접목,확산되어짐에 따라보험상품 설계시 예상할 수없었고\n따라서 대처할 수없게된새로운 위험에 대비한 복합보험상품도 등장하고 있지만 (InsurTech 보험사로\n알려진 Relm보험사가 올1월출시한 PONTAAI 상품이 대표적 )의료보험시장에서도 관련특화된\n상품들이 속속등장하고 있습니다 .다만2024년8월부터 시행되고 있는EUAI법이진단,진료에서의\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n6AID Vol. 6\n의사결정 등의료분야에서의 AI활용을 고위험 (high", "source": "data/raw/Tech Legal Insights.pdf", "page": 10, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "25781a9f9caf305f5eafa075347b355c", "text": "ail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n6AID Vol. 6\n의사결정 등의료분야에서의 AI활용을 고위험 (high-risk)영역으로 간주하면서 위험관리시스템을 활성\n화하여야만 하고,고품질의 데이터관리체제와 이용자에 대한정보제공의 투명성과 정확성 ,인간에 의한\n감시체제 등을의무화하고 있으며 ,이런의무이행의 최종시한이 늦어도 EUAI법시행후2년내인 내년\n8월까지로 정해져 있습니다 .\n보험사기를 탐지하고 ,가입자의 신용평가 ,행동패턴 분석등에도 물론AI는활용되어질 수있지만 ,특히\n비용절감차원에서 보험사가 관심을 가지게 되는‘보험가입자의 행동패턴을 AI가분석해 사기가능성을\n측정’하는행위는 고위험 AI로분류되어 엄격한 규제를 받기때문에 현재까지 대체로는 개인맞춤형 보\n험상품개발 및제공,개인건강정보 기반의 위험평가와 보험료 할인,환급내지기존의료과실책임보험\n(medical malpractice insurance) 약관에서 AI관련특정위험을 추가하거나 면책하는 등의특약을 첨가하거\n나기술수준을 고려하여 ‘의사의 최종검토’프로세스를 중요하게 강조하는 것정도가 의료보험상품의\n대체적 변화모습이라고 할수있습니다 .\n물론AI가빨리확산되고 있는AI의료기기 제조사 및개발사를 대상으로 하는새로운 관련보험상품도\n경쟁적으로 개발되고 있고의료기관이 보유한 민감한 환자의료정보를 AI를활용하여 처리,진단,수술\n등에활용함에 따른사이버 책임보험 상품도 등장하고 있습니다 .또한Anthem, Aetna등미국의 대형보\n험사들이 웨어러블데이터 ,전자건강기록 ,생활패턴 데이터등을 AI로분석해 개", "source": "data/raw/Tech Legal Insights.pdf", "page": 11, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "479a4ed50ea258f80d1149cea55a6bcb", "text": "술\n등에활용함에 따른사이버 책임보험 상품도 등장하고 있습니다 .또한Anthem, Aetna등미국의 대형보\n험사들이 웨어러블데이터 ,전자건강기록 ,생활패턴 데이터등을 AI로분석해 개인별 위험도를 정확히 평\n가,건강한 생활을 지속하는 가입자에게는 보험료 할인혜택을 제공하고 있으며 ,AI챗봇이 1차건강상담\n을제공하고 필요시 의료진과 연결하여 주는서비스가 포함된 영국의 Babylon Health사보험상품처럼 텔\n레메디슨과 연계된 보험상품들도 시장에서 판매되고는 있습니다 .\n3-2.현대적 사회보장제도의 일환으로 독일에서 19세기말 노동자들을 위한건강보험제도가 처음시작\n된이래공공보험과 민영보험의 역할분담을 둘러싼 기여비중의 차이는 있을지 언정‘진료이후의 비용\n부담을 사후보전하는 방식’을공통으로 각국의 의료보험제도는 오랫동안 운영되어 왔습니다 .이에따\n라보험사고와 보험요율을 결정하기 위해과거의 데이터를 모아보험상품을 개발하고 판매하여 왔었지\n만디지털과 AI의영향으로 이제의료보험 자체가 ‘사전에 예측하고 예방하는 ’(Predict &Prevent) 방향으\n로의변화를 보이고 있습니다 .\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n7AID Vol. 6\n즉질병이 발생하기 전에,치료가 시작되기 전에거의실시간으로 웨어러블 건강보조도구 등을통해서\n개인의 전자건강데이터를 체크할 수있음은 물론식사,흡연,음주,일패턴", "source": "data/raw/Tech Legal Insights.pdf", "page": 12, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "1807cdbaa74efcbb2a64a7e0c13d8f45", "text": ".\n7AID Vol. 6\n즉질병이 발생하기 전에,치료가 시작되기 전에거의실시간으로 웨어러블 건강보조도구 등을통해서\n개인의 전자건강데이터를 체크할 수있음은 물론식사,흡연,음주,일패턴,습관등의관련변수까지 고\n려한정기적 온라인 건강진단도 간편하게 할수있게되고유전자 정보까지 활용되어지면서 노후의 건\n강관리또한체계적으로 가능하게 됨에따라위험을 예측하고 사전예방하는 디지털의료보험 시스템\n도입이 실제로 이뤄지게 된것입니다 .특히AI의접목으로 학습데이터 기반의 보험가입자별 잠재적 질병\n가능성 ,수술후의 후유증 ,부작용을 예측하는 개인맞춤형 서비스 제공은 물론이고 분야별 관련데이터\n의정밀화를 바탕으로 약복용여부 ,낙상,만성질병 가능성의 경고와 음식,운동,정기검사권고 등의다\n양한보험관련 서비스 개발,제공도 현실적으로 가능하게 되었습니다 .\n이런결과는 보험가입자는 물론이고 보험회사에게도 비용지출의 감소와 위험관리의 체계화 등공통\n이익을 준다는 점때문에 개인은 물론이고 의료기관 ,의료데이터를 활용하는 관련기관등까지 이용할\n수있는AI관련종합의료보험 내지특화된 상품개발로 나타나게 되고특히민간의료보험시장의 변화는\n더욱경쟁적으로 나타날 것으로 전망됩니다 .\n보험시장의 이러한 혁명적 변화를 가능하게 하는대전제는 AI를접목하여 의료데이터의 공유와 활용을\n가능하게 하는개인디지털건강기록의 통합,관리및활용시스템 구축,활용이고 현재진행되고 있는우\n리나라의 MyHealthway 사업,또한올3월에발효된 유럽의 EHDS (European Health DataSpace) 법이그\n런시스템 구상의 구체적 추진예들입니다 .(이들내용에 대해서는 지난AID5호를참", "source": "data/raw/Tech Legal Insights.pdf", "page": 13, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "d18d68dd2896208666b6ee2b1e6ec22d", "text": "ay 사업,또한올3월에발효된 유럽의 EHDS (European Health DataSpace) 법이그\n런시스템 구상의 구체적 추진예들입니다 .(이들내용에 대해서는 지난AID5호를참조)\n서울특별시 서초구 서초중앙로 24길10,13층,14층(서초동 , 316타워)  |  Tel: 02 -3477-8695  |  Fax: 02 -3477-8694\nE-mail: lin@law -lin.com  |  © 2017 LIN. All Rights Reserved.\n8AID Vol. 6\n의료과실, 제조물책임, 데이터보호 등과같은전통적쟁점외에 생성형      AI를이용자가 검색과상담의도구로자주사용하게 되면서환각         (hallucination)을통해가짜의학정보를 생성해내고 잘못된진료와처방까지 만들어내는 등새로운법적이슈도등장하고 있습니다               . 반면, MS가6월30일숙련된의사그룹보다    4배높은진단정확도를 자랑하는     AI 진단오케스트레이터  ‘ MAI-DxO’를공개함으로써 의료   AI의또다른혁명적변화를예고하기도 했습니다       . <매월발간하는 법무법인 린    TMT그룹AI산업센터의 뉴스레터인 AID에대한질문   , 조언등은 구태언TMT 전문그룹장(tekoo@law-lin.com), 방석호AI 산업센터장(shbang@law-lin.com), 설기석구성원변호사   (ksseol@law-lin.com)에게보내주십시오 .>\n의료과실 , 제조물책임 , 데이터보호 등과같은전통적 쟁점외에 생성형 AI를이용자가 검색과 상담의 도구로 자주\n사용하게 되면서 환각(hallucination) 을통해가짜의", "source": "data/raw/Tech Legal Insights.pdf", "page": 14, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "c46bb1cbfce0f10a0884d8d345c61a0a", "text": "시오 .>\n의료과실 , 제조물책임 , 데이터보호 등과같은전통적 쟁점외에 생성형 AI를이용자가 검색과 상담의 도구로 자주\n사용하게 되면서 환각(hallucination) 을통해가짜의학정보를 생성해내고 잘못된 진료와 처방까지 만들어내는 등\n새로운 법적이슈도 등장하고 있습니다 . 반면, MS가6월30일숙련된 의사그룹보다 4배높은진단정확도를\n자랑하는 AI 진단오케스트레이터 ‘MAI-DxO’를공개함으로써 의료AI의또다른혁명적 변화를 예고하기도 했습니다 . \n<매월발간하는 법무법인 린TMT그룹AI산업센터의 뉴스레터인 AID에대한질문, 조언등은\n구태언 TMT 전문그룹장 (tekoo@law -lin.com ), 방석호 AI 산업센터장 (shbang@law -lin.com ), \n설기석구성원변호사 (ksseol@law -lin.com )에게보내주십시오 .>", "source": "data/raw/Tech Legal Insights.pdf", "page": 15, "kind": "instructor", "title": "Tech Legal Insights.pdf"}
{"id": "8a3e874103bdfbc77c9d3bc0f52ce5e9", "text": "比較私法 第29卷 4號(통권 제99호) 2022年 11月 217~251 면\nThe Korean Association of Comparative Private Law Vol.29 No.4 November.  2022. pp.217~251\nhttps://doi.org/10.22922/jcpl.2022.29.4.217\n 217\n의료 인공지능의 활용을 둘러싼 법적 과제: \n규제의 진화 및 책임의 배분을 중심으로*\n1) 박 혜 진**\n목  차\nⅠ. 들어가며\nⅡ. 인공지능 의료기기의 규제 및 도입 \n현황Ⅲ. 인공지능 의료기기 오작동으로 인한 \n책임 분배\nⅣ. 마치며\n국문초록\n인공지능 기술의 발달은 의료를 혁신하고 의료서비스의 질을 향상시킬 것으로 기대되고 있다. 그러\n나 인공지능 의료기기가 오작동하는 경우에는 의료진의 최선의 의사결정을 방해하거나 환자에게 나쁜 \n결과를 가져올 위험성이 있다. 이처럼 국민의 생명·건강과 직결되는 인공지능 의료기기를 어떻게 규제\n할 것인지 , 또 인공지능 의료기기로 인하여 발생한 손해에 대한 책임을 누구에게 지울 것인지는 그 자\n체로도 중요한 문제일 뿐만 아니라 앞으로의 기술발전의 방향과 속도와도 밀접한 관련이 있다. 이 글\n에서는 인공지능 의료기기의 규제와 관련하여 우리나라와 미국 등의 규제당국이 대응해 온 문제들을 \n크게 세 단계로 나누어 조망하고 , 우리나라에서 대응해야 할 남아있는 문제들을 살펴본다 . 또한, 인공\n지능 의료기기의 오류로 인하여 환자에게 나쁜 결과가 발생한 경우의 책임 문제에 관하여 , 의사의 책\n임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 계약", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 1, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "3865103fb8852acabedae341f2827787", "text": ", 인공\n지능 의료기기의 오류로 인하여 환자에게 나쁜 결과가 발생한 경우의 책임 문제에 관하여 , 의사의 책\n임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 계약을 통한 위험 이전 가능성 , 마\n지막으로 공동사업책임 (common enterprise liability) 또는 기금 등을 통한 특별보상제도의 도입 필요성에 \n대하여 전반적으로 검토하면서 , 앞으로 더욱 깊이 있는 연구나 논의가 필요한 부분을 가늠해 보고자 \n한다. \n❙주제어 ❙\n의료 인공지능 , 인공지능 의료기기 , 의료기기 규제, 의료과오책임 , 인폼드 컨센트 , 설명의무 , 제조물 \n책임\n * 이 논문은 한양대학교 교내연구지원사업으로 연구되었음 (HY-202100000003545)\n** 법학박사 (J.S.D.), 한양대학교 법학전문대학원 , 부교수\n\n비교사법 제29권 4호(통권 제99호)\n218Ⅰ. 들어가며\n10년 전인 2012년, 선 마이크로시스템 (Sun Microsystems) 의 공동창업자이자 전설적인 벤처투자\n자인 비노드 코슬라 (Vinod Khosla) 는 미국 헬스케어 벤처펀드인 록헬스 (Rock Health) 가 주최한 의\n료 혁신에 관한 컨퍼런스에서 “기계가 80퍼센트의 의사를 대체하게 될 것”이라고 말해 큰 논란\n을 불러일으킨 적이 있다.1) 그 후로 인공지능 기술은 빠르게 발전하여 다양한 의료 분야에서 임\n상 및 연구에 활용되고 있다.2) 인공지능 알고리즘이 마모그램 영상을 보고 유방암의 발병을 영\n상의학과 전문의보다 더 정확하게 예측하고 ,3) 날짜와 날씨 정보를 이용하여 심장마비 발병 위험\n을 예측하기도", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 2, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "d2b05bbf7339dce757dcfb4b40ab2cec", "text": "다.2) 인공지능 알고리즘이 마모그램 영상을 보고 유방암의 발병을 영\n상의학과 전문의보다 더 정확하게 예측하고 ,3) 날짜와 날씨 정보를 이용하여 심장마비 발병 위험\n을 예측하기도 하며,4) 입원환자의 전자의무기록 데이터를 5분마다 실시간으로 분석하여 패혈증 \n쇼크의 징후를 조기에 포착하기도 한다.5) \n인공지능 기술의 발달은 의료 빅데이터에서 새롭고 중요한 정보를 추출함으로써 의료를 혁신\n하고 의료서비스의 질을 향상시킬 것으로 기대되고 있다.6) 이미 미국의 의료기관의 3분의 1이 \n환자의 영상 분석 등에 인공지능을 활용하고 있다고 한다.7) 현재 인공지능이 의료에서 활용되는 \n대표적인 분야는 의료 영상 분석(medical image analysis) 과 임상 의사결정 지원(clinical decision \nsupport) 이다.8) 의료 영상이나 병리학 슬라이드를 분석하여 진단에 도움을 주고, 환자의 의료 기\n록을 분석하여 의료진에게 알람을 보내거나 예측결과를 제공함으로써 임상 의사결정의 질을 높\n이고 오류를 줄여주는 역할을 하고 있다.9) \n그러나 인공지능 의료기기가 오작동하는 경우에는 의료진의 최선의 의사결정을 방해하거나 \n환자에게 나쁜 결과를 가져올 위험성이 있다. 이처럼 국민의 생명·건강과 직결되는 인공지능 의\n1)Liat Clark, Vinod Khosla: Machines will replace 80 percent of doctors, Apr. 9, 2012. Wired, available at: \nhttps://www.wired.co.uk/article/doctors-replaced-with-", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 3, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "bfed1ec44ffeee96b764b043b361de37", "text": " doctors, Apr. 9, 2012. Wired, available at: \nhttps://www.wired.co.uk/article/doctors-replaced-with-machines.\n2)보건의료영역에 인공지능은 임상진단 , 질병 예측, 영상판독이나 상체분석 , 수술로봇 , 의학연구 , 앱 기반 의료\n서비스 , 건강 및 사회복지 자원의 효율적 배분, 공중보건을 위한 조기예측 등에 적용되고 있다. 이인영 , “보건\n의료에서의 인공지능 적용과 관련된 법적 과제에 대한 개관”, 「한국의료법학회지 」, 제27권 제2호(2019), \n40~44면.\n3)Jessica Hamzelou, AI system is better than human doctors at predicting breast cancer, New Scientist (Jan. 1, \n2020). \n4)BMJ, Machine learning (AI) accurately predicts cardiac arrest risk (May 17, 2021), available at \nhttps://www.bmj.com/company/newsroom/machine-learning-ai-accurately-predicts-cardiac-arrest-risk/.\n5)Eliza Strickland, Hospitals Roll out AI systems to Keep Patients From Dying of Sepsis, IEEE Spectrum (Oct. \n19, 2018).\n6)U.S. Food and Drug Admin., Proposed Regulatory ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 4, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "89979eb7fa6d5c5cb5daabe648233696", "text": "m Dying of Sepsis, IEEE Spectrum (Oct. \n19, 2018).\n6)U.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine \nLearning Based Software as a Medical Device (SaMD) 2 (2019), https://www.fda.gov/media/122535/download.\n7)Jessica Kent, One Third of Orgs Use A.I. in Med. Imaging, Health IT Analytics (Jan. 28, 2020), \nhttps://healthitanalytics.com/news/one-third-of-orgs-use-artificial-intelligence-in-medical-imaging.\n8) Frank Griffin, Artificial Intelligence and Liability in Health Care, 31 Health Matrix 65, 73-78 (2021).\n9) Ibid.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 219\n료기기를 어떻게 규제할 것인지 (사전적 규제), 또 인공지능 의료기기의 오작동으로 인하여 발생\n한 손해에 대한 책임을 누구에게 지울 것인지 (사후적 규제)의 문제는 그 자체로도 중요한 문제\n이고, 앞으로의 기술발전의 방향 및 속도와도 밀접한 관련이 있다. 과도한 규제를 하게 되면 자\n칫", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 5, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "1cf048ae6723908c8163b2911268bf65", "text": "한 책임을 누구에게 지울 것인지 (사후적 규제)의 문제는 그 자체로도 중요한 문제\n이고, 앞으로의 기술발전의 방향 및 속도와도 밀접한 관련이 있다. 과도한 규제를 하게 되면 자\n칫 이로 인하여 산업 발전이 저해될 수도 있고, 적절한 규제가 없이는 의사나 환자가 안전의 우\n려로 최신의 인공지능 의료기기 사용을 꺼리게 될 수도 있기 때문이다 . \n우선, 인공지능 의료기기를 어떻게 규제할 것인가 (사전적 규제)에 관하여는 기존에 인공지능 \n소프트웨어를 의료기기로 보아 규제할 수 있는지에 관한 문제를 다루거나10) 인공지능 의료기기 \n관련 규제 현황을 개괄한 연구11)가 있었다 . 이 글에서는 인공지능 의료기기의 규제와 관련하여 \n우리나라와 미국의 규제당국이 대응해 온 문제들을 크게 규제의 진화의 3단계로 나누어 살펴보\n고,12) 우리가 대응해야 할 남아있는 문제들을 짚어 본다. 다음으로 , 인공지능 의료기기의 오류와 \n관련한 민사책임 문제(사후적 규제)에 관하여는 , 주로 의사의 책임과 관련하여 논의가 이루어져 \n왔을 뿐13) 의료기관이나 제조업체 등 다른 책임주체들의 책임도 함께 검토한 연구는 거의 없었\n다.14) 이 글에서는 의사의 책임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 \n계약을 통한 위험 이전 가능성 , 마지막으로 공동사업책임 (common enterprise liability) 또는 기금 \n등을 통한 특별보상제도의 도입 필요성에 대하여 전반적으로 검토하면서 , 인공지능 의료기기와 \n관련된 책임에 관한 논의의 외연을 확장하고 , 앞으로 더욱 깊이 있는 연구 및 토론이 필요한 부\n분", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 6, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "9479901f78f88d58169bc3c06dee75ab", "text": "별보상제도의 도입 필요성에 대하여 전반적으로 검토하면서 , 인공지능 의료기기와 \n관련된 책임에 관한 논의의 외연을 확장하고 , 앞으로 더욱 깊이 있는 연구 및 토론이 필요한 부\n분을 가늠해 보고자 한다. 다만 이 글에서는 의료 빅데이터를 둘러싼 개인정보 보호 등의 문제\n와 인공지능 의료기기 활용과 관련한 형사책임에 관한 문제는 직접적으로 다루지 않는다 .\n우선, 아래에서는 (II.) 인공지능 의료기기가 어떻게 규제되고 있고, 얼마나 시장에 나오고 있는\n10)김재선 , “인공지능 의료기기 위험관리를 위한 규범론적 접근-인공지능 소프트웨어 규범화 논의를 중심으로 -”, \n「공법연구」, 제46집 제2호(2017); 엄주희 /김소윤 , “인공지능 의료와 법제”, 「한국의료법학회지 」, 제28권 \n제2호(2020).\n11)김광수 , “인공지능 기반 과학기술과 국민의 권익구제 -자율주행차 , 드론 및 의료기기를 중심으로 -”, 「토지공\n법연구」, 제85집(2019).\n12)본 논문에서는 지면의 한계상 유럽의 인공지능 의료기기 규제에 대하여는 다루지 않는다 . 유럽의 인공지능 \n의료기기 규제에 관하여는 , Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, \nRegulatory responses to medical machine learning, 7 J. L.& Biosciences 1 (2020) 참조.\n13)배현아 , “보건의료법제 하에서 인공지능기술의 의료영역 도입의 의의와 법적 문제”, 「법조」, 제724집\n(2017) (본격적으로 인공지능 의", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 7, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "cb8d6cd594ffb35866d50e5ee72f959e", "text": "nces 1 (2020) 참조.\n13)배현아 , “보건의료법제 하에서 인공지능기술의 의료영역 도입의 의의와 법적 문제”, 「법조」, 제724집\n(2017) (본격적으로 인공지능 의료기기가 임상에 도입되기에 앞서 인공지능 의료기기와 관련한 규제법적 , 책\n임법적 이슈를 폭넓게 다루었음 ); 백경희 /장경화 , “인공지능을 이용한 의료행위와 민사책임에 관한 고찰”, \n「법조」, 제724집(2017) (인공지능 의료기기의 본격적 도입에 앞서 인공지능 의료기기를 활용하는 의료행\n위의 특수성과 인공지능을 활용한 의료행위시 발생할 수 있는 민사책임 문제를 폭넓게 다루었음 ); 설민수 , \n“머신러닝 인공지능과 인간전문직의 협업의 의미와 법적 쟁점: 의사의 의료과실 책임을 사례로 ”, 「저스티\n스」, 제163호(2017) (인간 전문직과 머신러닝 인공지능의 협업이라는 점에 착안하여 인공지능 의료기기를 \n활용하는 의사의 책임 문제를 다룸); 정채연 , “의료 인공지능의 법적 수용을 위한 시론적 연구”, 「법학논\n총」, 제45권 제3호(2021) (의료 인공지능을 둘러싸고 제기되는 법적, 사회적 , 윤리적 쟁점들을 조망함 ).\n14)이중기 /이재현 , “의료 AI에 대한 규제체제와 책임의 귀속-진단AI와 수술로봇을 중심으로 -”, 「홍익법학」, 제\n21권 제4호(2020) (진단 AI와 수술로봇의 이용과 관련하여 책임의 귀속 문제를 다룸).\n\n비교사법 제29권 4호(통권 제99호)\n220지에 대한 이해를 돕기 위하여 인공지능 의료기기의 정의 및 규제대상으로서의 특수성 , 국내외 \n규제 이슈 및 아직 해결되지 않은 문제들을 차", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 8, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "a8cb3437806cbb93887355b5887e9616", "text": "법 제29권 4호(통권 제99호)\n220지에 대한 이해를 돕기 위하여 인공지능 의료기기의 정의 및 규제대상으로서의 특수성 , 국내외 \n규제 이슈 및 아직 해결되지 않은 문제들을 차례로 짚어본다 . 그 다음으로 (III.), 인공지능 의료기\n기의 오작동으로 인하여 환자에게 나쁜 결과가 발생한 경우 그 책임을 어떻게 분배할 것인지의 \n문제에 관하여 , 의사의 의료과오책임 및 설명의무위반 책임, 의료기관의 책임, 인공지능 의료기\n기 제조업자의 책임, 보험 등 위험의 이전 방안 및 공동사업책임 또는 기금 등 무과실 보상제도\n를 살펴본다 . 마지막으로 (IV.) 앞으로 연구자와 이해관계자들의 관심과 논의가 필요한 부분을 다\n시 한번 언급하면서 이 글을 끝맺는다 . \nⅡ. 인공지능 의료기기의 규제 및 도입 현황\n1. 인공지능 의료기기의 정의\n인공지능 의료기기에 대한 본격적인 논의에 앞서 인공지능 의료기기란 무엇을 의미하는지 짚\n고 넘어갈 필요가 있다. 비록 인공지능의 정의에 대한 논란은 아직 완전히 정리되지 않았지만 , \n의료기기 규제당국의 자율적 모임인 국제의료기기규제당국자포럼 (International Medical Device \nRegulators Forum, IMDRF) 의 인공지능 의료기기 실무 그룹(Artificial Intelligence Medical Device \nworking group)은 최근 용어의 통일을 위하여 인공지능 의료기기 국제 공통 지침안을 발간하였\n다.15) 따라서 인공지능 의료기기를 다루는 이 글에서는 위 지침안을 기준으로 논의를 진행하기\n로 한다. 위 지침안에 따르면 , 인공지능이란 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 9, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "5b573d834a2bf5da9511c7f05a8c994f", "text": "의료기기 국제 공통 지침안을 발간하였\n다.15) 따라서 인공지능 의료기기를 다루는 이 글에서는 위 지침안을 기준으로 논의를 진행하기\n로 한다. 위 지침안에 따르면 , 인공지능이란 , 알고리즘이나 모델을 이용하여 학습, 의사결정 , 및 \n예측 등을 행하도록 하는 컴퓨터 공학 및 통계학의 한 분야이다 .16) 인공지능의 하위분류인 기계\n학습(Machine Learning, ML)은 컴퓨터 알고리즘이 일일이 프로그래밍하지 않아도 데이터를 학습\n하여 특정 과제(task)를 수행할 수 있게 하는 기술이다 .17) 기계학습 (ML)의 하위분류인 딥러닝\n(Deep Learning) 은 컴퓨터가 방대한 양의 데이터를 접하면서 스스로 학습하도록 하는 방식으\n로,18) 최근 컴퓨터 비전(Computer Vision) 이나 자연어 처리(Natural Language Processing) 등에서 \n비약적 기술 발전이 있었던 분야이지만 , 다른 한편으로는 가장 불투명성 (opacity) 이 문제로 지적\n되는 분야이기도 하다. 기계학습을 이용한 기술은 흔히 인공지능 (AI) 또는 인공지능 /기계학습\n(AI/ML) 으로 일컬어지기도 하는데 , 의료기기에 기계학습 기술을 접목시킨 의료기기 , 즉 기계학습 \n15)IMDRF AIMD Working Group,  Machine Learning-enabled Medical Devices —A Subset of Artificial \nIntelligence-enabled Medical Devices: Key Terms and Definitions, 16 September 2021.\n16)Ibid.", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 10, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "ccc85ce74672a7bb8832c2df37920502", "text": "ficial \nIntelligence-enabled Medical Devices: Key Terms and Definitions, 16 September 2021.\n16)Ibid., p.4 (“a branch of computer science, statistics, and engineering that uses algorithms or models to perform \ntasks and exhibit behaviors such as learning, making decisions and making predictions”).\n17)위의 글 (“a subset of AI that gives computers the ability to learn without being explicitly programmed“).\n18) 위의 글 (“[a] subset of ML: enable computer to teach itself by exposing it to vast amount of data”).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 221\n의료기기 (Machine Learning-enabled Medical Devices, MLMD) 는 실제 사용되는 환경에서 경험을 \n통하여 성능을 향상시킬 수 있다는 것이 가장 큰 장점이다 .19) 이 글에서는 좀 더 넓은 개념인 \n인공지능 의료기기를 다루고 있으나 , 규제법적 , 책임법적으로 주로 문제가 되는 것은 인공지능 \n의료기기 중 기계학습 의료기기의 경우가 될 것이다 . \n2. 규제 대상으로서의 인공지능 의료기기", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 11, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "9e04c11e32c3fbf32651fa63956458b1", "text": "기기를 다루고 있으나 , 규제법적 , 책임법적으로 주로 문제가 되는 것은 인공지능 \n의료기기 중 기계학습 의료기기의 경우가 될 것이다 . \n2. 규제 대상으로서의 인공지능 의료기기의 특성\n인공지능 의료기기 , 특히 기계학습 의료기기는 여타 소프트웨어 의료기기와 다른 몇 가지 특\n징을 가지고 있다. 첫 번째 특징은 불투명성 (opacity) 이다. 인공지능 의료기기에 사용되는 알고리\n즘이 인풋과 아웃풋 사이에 어떤 관계를 포착하는지 정확히 이해할 수 없고, 설명할 수도 없어 \n불투명 (non-transparent) 하다는 점을 들어 인공지능 의료기기를 블랙박스 의료(blackbox medicine) 라\n고 부르기도 한다.20) 특히 뒤에서 보겠지만 이러한 의료기기를 이용하여 의료행위를 하는 경우 \n의사의 책임과 관련하여도 인공지능 의료기기의 불투명성이 문제가 된다. \n두 번째 특징은 적응성 (adaptability) 으로, 새로운 데이터를 접하면 그에 맞추어 알고리즘이 변\n화하는 성질을 말한다 . 인공지능 의료기기가 잠긴 상태에 있는 경우, 즉 새로운 데이터를 접하여\n도 알고리즘이 변화하지 않는 의료기기를 “잠긴 의료기기 (locked device)” 라고 부르고 , 새로운 데\n이터를 접하면서 그 알고리즘이 변화하는 의료기기는 “적응하는 의료기기 (adaptive device)” 라고 \n부른다 . 바로 이 계속하여 변화하는 (continuous learning) 특성 때문에 인공지능 의료기기의 규제가 \n쉽지 않다.\n인공지능 의료기기에서 주목해야 할 또 하나의 특징은 잠재적 편향성 (bias)이다.21) 이는 대", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 12, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "726a58781d6db908d3f5c99c477b65c4", "text": "nuous learning) 특성 때문에 인공지능 의료기기의 규제가 \n쉽지 않다.\n인공지능 의료기기에서 주목해야 할 또 하나의 특징은 잠재적 편향성 (bias)이다.21) 이는 대표\n성이 없는 데이터 , 기존의 의료에서의 편향을 반영하는 데이터 , 개발자의 편향 등을 이유로 발생\n할 수 있다. 예컨대 , 대표성이 없는 데이터로 훈련된 심근병증 유전자 시험 알고리즘은 백인에 \n대해 다른 인종에서보다 높은 성능을 보였다 .22) 나아가 , 대형병원에서 전문가가 진료하는 환경에\n서 잘 기능하도록 훈련된 알고리즘은 그와 달리 자원이 부족한 환경에서는 적절하고 안전하며 \n19) 위의 글.\n20)인공지능 의료기기의 불투명성에 관한 논의로는 , W. Nicholson II Price, Black-Box Medicine, 28 Harv. J. L. \n& Tech. 419, 421 (2015); W. Nicholson Price II, Regulating Black-Box Medicine, 116 Mich. L. Rev. 421 \n(2017); Boris Babic et al., Beware Explanation from AI in Healthcare, 373 Science 284 (2021); Boris Babic \n& Sara Gerke, Explaining Medical AI is Easier Said than Done, Stat, 21 July 2021, available at: \nhttps://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-d", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 13, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "a7a43cda7a29142ed846d79ee75b958b", "text": "y 2021, available at: \nhttps://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-done.\n21)Griffin, 위의 글, 82~83면 (인공지능이 편향성을 나타낼 수 있는 이유로 특정 인구집단이 과소대표\n(under-represenation) 되는 경우, 대표성을 결여한 데이터 수집, AI가 불공정하게 적용되는 경우, 개발자나 사\n용자의 편향을 반영하는 경우를 언급함 ); Ziad Obermeyer et al., Dissecting racial bias in an algorithm used \nto manage the health of populations, 366 Science 447 (2019). \n22)Latrice G. Landry, Heidi L. Rehm, Association of Racial/Ethnic Categories with the Ability of Genetic Tests \nto Detect a Cause of Cardiomyopathy, 3 JAMA Cardiol 341 (2018).\n\n비교사법 제29권 4호(통권 제99호)\n222경제적인 치료법을 추천하지 못할 수 있다는 상황별 편향(‘contextual’ bias)도 문제될 수 있다.23) \n편향성 문제는 인공지능 의료기기를 채택하여 이용하는 의사나 의료기관의 책임은 물론 인공지\n능 의료기기 제조업자의 책임에도 영향을 줄 수 있다.\n다음에서는 이와 같은 인공지능 의료기기의 특성24)을 고려할 때 인공지능 의료기기를 효과적\n으로 적절하게", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 14, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "403c2172d8870d2e7f0ca42ce9f4c77f", "text": " 책임은 물론 인공지\n능 의료기기 제조업자의 책임에도 영향을 줄 수 있다.\n다음에서는 이와 같은 인공지능 의료기기의 특성24)을 고려할 때 인공지능 의료기기를 효과적\n으로 적절하게 하기 위한 노력을 미국과 우리나라 위주로 살펴본다 .\n3. 인공지능 의료기기의 규제의 진화\n인공지능 의료기기를 어떻게 규제할 것인지에 관한 논의는 크게 세 단계로 나누어 설명할 수 \n있다. 우선, 인공지능 의료기기가 주로 소프트웨어의 형태를 띤다는 점에서 , 소프트웨어를 의료\n기기로 포섭하여 엄격한 의료기기에 대한 규제를 적용할 것인지가 문제되었다 . 다음으로 , 소프트\n웨어의 특성을 고려하여 기존의 의료기기 규제와 다른 새로운 방식을 고려해야 하는지에 대한 \n고민이 있었다 . 마지막으로 , 시판 후에 실제 사용하는 과정에서 새로운 데이터에 맞추어 적응하\n는(adaptive) 인공지능 의료기기의 경우 적절한 규제 방안이 무엇인지에 대하여 지금도 논의가 진\n행 중이다 .\n(1) 소프트웨어도 의료기기에 포함되는가 ?\n미국에서 의료기기의 안전성을 감독하는 연방 규제기관은 식품의약품안전청 (U.S. Food and \nDrug Administration, FDA)이다. 1938년 연방 식품의약품화장품법 (Food, Drug and Cosmetics Act)이 \n제정되면서 의료기기에 대한 개념이 도입되었으나 , 본격적으로 의료기기의 안전관리 제도가 도\n입된 것은 1976년 의료기기 개정법 (The Medical Device Amendments) 에서 등급분류 체계와 중저\n위험도 의료기기에 대한 시판 전 본질적 동등성 평가제도 (501(k)) ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 15, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "05747f61ed08d1eb46f52dbbdadf121e", "text": "76년 의료기기 개정법 (The Medical Device Amendments) 에서 등급분류 체계와 중저\n위험도 의료기기에 대한 시판 전 본질적 동등성 평가제도 (501(k)) 및 고위험도 의료기기에 대한 \n시판 전 평가 제도(Premarket approval, PMA)를 도입하면서 부터였다 .25) 의료기기를 안전성과 유\n효성에 대한 우려 정도에 따라 3개의 등급(Class I, Class II, Class III)으로 나누고 , 그 등급에 따\n라 얼마나 엄격한 심사를 거쳐 시판을 허용할 것인지 여부를 결정하게 된다. 1등급(Class I) 의료\n23) W. Nicholson Price II, Medical AI and Contextual bias, 33 Harv. J.L. & Tech. 65(2019).\n24)위에서 언급한 특성들 외에도 인공지능 의료기기에서 간과하지 않아야 할 측면은 바로 보안(cybersecurity) \n문제이다 . 인공지능 의료기기는 주요 구성부분이 소프트웨어로서 인터넷이나 센서에 연결된 경우가 많고, 상\n대적으로 고가에 거래가 가능한 의료 데이터를 다루기에 사이버 공격의 표적이 되기 쉽다. 뿐만 아니라 인\n공지능 알고리즘에 내재한 취약점을 노리는 적대적 공격(adversarial attack)에 노출될 가능성도 있다. 이 글에\n서 인공지능 의료기기의 보안 위험에 관한 규제나 책임 문제까지 다루기에는 지면이 부족하나 , 이 문제는 \n인공지능 의료기기 , 더 넓게는 소프트웨어 의료기기의 사용 증가와 함께 더 많은 관심이 필요한 이슈임은 \n분명하다 .\n25)김병관 /양석조 , “임상적 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 16, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e1ee64614c3d158a83af3d0391f03bd8", "text": " 부족하나 , 이 문제는 \n인공지능 의료기기 , 더 넓게는 소프트웨어 의료기기의 사용 증가와 함께 더 많은 관심이 필요한 이슈임은 \n분명하다 .\n25)김병관 /양석조 , “임상적 관점에서의 의료기기 관리제도 개선방안 연구”, 「과학기술법연구 」, 제25집 제4호\n(2019), 10면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 223\n기기는 비교적 단순하며 오랫동안 안전하게 사용되어 온 것으로서 , 압설자 (tongue depressor), 팔\n걸이(arm sling) 등이 이에 해당되고 , 통상 시판 전 평가에서 면제된다 .  2등급(Class II) 의료기기\n는 안전성과 유효성에 대한 우려가 1등급 의료기기에 비해 큰 경우로서 , 인슐린 펌프, 엑스레이 \n기계 등이 통상 이에 해당하며 , 510(k) 절차라는 비교적 간단한 시판 전 평가 또는 De Novo \nclassification 절차26)를 거쳐 시장에 나오게 된다. 3등급(Class III) 의료기기는 가장 엄격한 시판 \n전 허가(Premarket Approval, PMA) 절차를 거치도록 되어 있는데 , 생명을 유지하거나 , 건강 침해 \n방지에 중요한 역할을 하는 의료기기 , 또는 질병이나 상해의 비합리적인 위험을 야기하는 의료\n기기, 예컨대 삽입형 제세동기 (implantable defibrillator) 같은 경우가 이에 해당한다 .27) 위 1976년 \n법에서는 의료기기를 정의하는 규정을 두고 있는데28) 소프트웨어가 의료기기에 해당하는지 여부\n가 중요한 이유는 , 의료기기로 포섭되는 순간", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 17, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "68d2811aabc4226f407012a4aede92d1", "text": " 이에 해당한다 .27) 위 1976년 \n법에서는 의료기기를 정의하는 규정을 두고 있는데28) 소프트웨어가 의료기기에 해당하는지 여부\n가 중요한 이유는 , 의료기기로 포섭되는 순간 의료기기에 대한 시판전후 (pre-marketing and \npost-marketing) 의 엄격한 규제가 적용되기 때문이다 .29) \n소프트웨어가 의료 현장에서 이용되는 경우가 빈번해 지면서 , 각국의 규제당국들이  의료 목\n적의 소프트웨어를 어떻게 규제할 것인지에 대해 관심을 가지기 시작했다 . 특히 의료목적의 소\n프트웨어 중 기존에 규제 대상으로 당연히 포함되었던 ‘의료기기의 일부로서의 소프트웨어\n(Software in a medical device, 이하 SiMD)’, 즉 하드웨어 의료기기의 구성부분 일부를 이루는 소\n프트웨어 외에도 , ‘의료기기로서의 소프트웨어 (Software as a medical device, 이하 SaMD)’, 30) 즉, \n하드웨어 의료기기의 일부를 이루지 않는 의료 목적의 소프트웨어에 대한 효과적 규제가 필요하\n다는 데 각국 규제당국들이 인식을 같이하였다 . 국제의료기기규제당국자포럼 (IMDRF) 의 SaMD \n26)De novo classifiation 절차란 기존에 허가받은 동등한 의료기기 (predicate device) 가 없는 중저위험의 의료기\n기에 적용되는 절차로서 , 이를 통해 1등급 또는 2등급 의료기기로 분류될 수 있다. FDA, De Novo Classific\nation Request, https://www.fda.gov/medical-devices/premarket-submi", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 18, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "c6c8a76abdd3bb498e66e8578a6969f7", "text": " 분류될 수 있다. FDA, De Novo Classific\nation Request, https://www.fda.gov/medical-devices/premarket-submissions-selecting-and-preparing-correct-submissio n/\nde-novo-classification-request.\n27)의료기기의 분류와 시판전 절차에 대하여는 , FDA, How to Study and Market Your Device, https://www.fda .\ngov/medical-devices/device-advice-comprehensive-regulatory-assistance/how-study-and-market-your-device.\n28)Food, Drug, and Cosmetics Act (FDCA) Section 201(h)(“An instrument, apparatus, implement, machine, contrivance, \nimplant, in vitro reagent, or other similar or related article, including a component part, or accessory which is:\n 1. recognized in the official National Formulary, or the United States Pharmacopoeia, or any supplement to \nthem, 2. intended for use in the diagnosis of disease or other conditions, or in the", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 19, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f13ab960908a53654018f903445f7203", "text": " supplement to \nthem, 2. intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, \nor prevention of disease, in man or other animals, or 3. intended to affect the structure or any function of the \nbody of man or other animals, and which does not achieve its primary intended purposes through chemical \naction within or on the body of man or other animals and which does not achieve its primary intended \npurposes through chemical action within or on the body of man or other animals and which is not dependent \nupon being metabolized for the achievement of its primary intended purposes. The term \"device\" does not \ninclude software functions excluded pursuant to section 520(0)”).\n29)Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 20, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "3fa64d0c8b5941d227139fbe1911442b", "text": "pursuant to section 520(0)”).\n29)Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory responses to medical \nmachine learning, 7 J. L.& Biosciences 1, 4-5 (2020) 참조.\n30)FDA, Software as a Medical Device, \nhttps://www.fda.gov/medical-devices/digital-health/software-medical-device-samd.\n\n비교사법 제29권 4호(통권 제99호)\n224실무그룹에서는 2013년부터 미국 식품의약품안전청 (FDA)이 주축이 되어 SaMD에 대한 규제에 \n관한 일련의 가이드라인을 마련하였다 .31)\n미국은 2015년 21세기 치료법 (21st Century Cures Act)을 제정하여 식품의약품화장품법 (FDCA)\n에서 정하는 의료기기에 포함되는 소프트웨어의 범위를 보다 명확히 하였다 . 위 법은 행정적 기\n능을 지원하는 소프트웨어 , 건강한 라이프스타일을 장려하는 소프트웨어 , 전자의무기록을 관리하\n는 소프트웨어 , 데이터를 전송·저장·변환하는 소프트웨어 , 그리고 일정한 조건을 만족하는 임상 \n의사결정 지원(clinical decision support) 소프트웨어를 규제 대상에서 제외하였다 .32) 또한 미국 식\n품의약품안전청 (FDA)은 가이드라인을 통해 현재로서는 심각한 의료 상황에 적용되는 임상 의사\n결정 보조 소프트웨어만을 규제하겠다는 입장을 명확히 밝혔", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 21, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f73cbacb749546279a600a1451a5c4f7", "text": "였다 .32) 또한 미국 식\n품의약품안전청 (FDA)은 가이드라인을 통해 현재로서는 심각한 의료 상황에 적용되는 임상 의사\n결정 보조 소프트웨어만을 규제하겠다는 입장을 명확히 밝혔다 .33)\n우리나라에서도 2003년 의료기기법이 제정된 이래 의료기기의 시판 전 및 시판 후 단계에서\n의 안전성 ·유효성의 관리가 이루어져왔는데 , 2018년에 기술발전과 국제적 기준을 반영하여 의료\n기기법 제2조 의료기기의 정의에 소프트웨어를 명시적으로 추가하였다 .34) 뿐만 아니라 그에 앞\n선 2017년에는 식약처가 세계 최초로 「의료용 빅데이터와 인공지능 (AI) 기술이 적용된 의료기\n기의 허가·심사 가이드라인 」을 마련하여 의료용 소프트웨어가 의료기기에 해당하는지 여부는 \n사용목적과 위해도를 고려하여 종합적으로 판단한다고 밝히고 , 의료기기에 해당하는 소프트웨어\n의 범위를 구체적으로 제시하였다 .35) 예컨대 의료용 빅데이터를 기반으로 의료영상 , 체외진단기\n기로부터 나온 시그널 , 신호 획득시스템 (심전계 , 뇌파계 등)에서 나오는 패턴 또는 시그널을 분\n석하여 진단·치료에 필요한 임상정보를 제공하는 소프트웨어는 의료기기에 해당하나 , 의료기관의 \n행정사무 (병실·재고관리 , 전자수속 등)를 지원하는 소프트웨어나 운동·레저 및 일상적인 건강관리 \n31)IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Key Definitions (2013); IMDRF \nSaMD Working Group, \"Software as a Medical Device\": Possibl", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 22, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "71596e874875329d1e7224689cf33090", "text": "e (SaMD): Key Definitions (2013); IMDRF \nSaMD Working Group, \"Software as a Medical Device\": Possible Framework for Risk Categorization and \nCorresponding Considerations (2014); IMDRF SaMD Working Group, Software as a Medical Device (SaMD): \nApplication of Quality Management System (2015); IMDRF SaMD Working Group, Software as a Medical \nDevice (SaMD): Clinical Evaluation (2017).\n32) 21st Century Cures ACt, sec. 3060.\n33)FDA, General Wellness: Policy for Low Risk Devices, Guidance for Industry and Food and Drug \nAdministration Staff, https://www.fda.gov/media/90652/download.\n34) 의료기기법 제2조(정의) \n① 이 법에서 \"의료기기 \"란 사람이나 동물에게 단독 또는 조합하여 사용되는 기구 · 기계 · 장치 · 재료 · \n소프트웨어 또는  이와 유사한 제품으로서 다음 각 호의 어느 하나에 해당하는 제품을 말한다 . 다만, \n「약사법 」에 따른 의약품과 의약외품 및  「장애 인복지법 」 제65조에 따른 장애인보조기구 중 의지\n(義肢)·보조기 (補助器 )는 제외한", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 23, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "6b4b1956d8c483131417e7bd6ec25910", "text": "나에 해당하는 제품을 말한다 . 다만, \n「약사법 」에 따른 의약품과 의약외품 및  「장애 인복지법 」 제65조에 따른 장애인보조기구 중 의지\n(義肢)·보조기 (補助器 )는 제외한다 . \n1. 질병을 진단·치료·경감·처치 또는 예방할 목적으로 사용되는 제품\n2. 상해(傷害) 또는 장애를 진단·치료 · 경감 또는 보정할 목적으로 사용되는 제품\n3. 구조 또는 기능을 검사 · 대체 또는 변형할 목적으로 사용되는 제품\n4. 임신을 조절할 목적으로 사용되는 제품\n35)식품의약품안전처 , 빅데이터 및 인공지능 (AI) 기술이 적용된 의료기기의 허가·심사 가이드라인 (민원인 안내\n서), 2017.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 225\n목적의 소프트웨어는 의료기기에 해당하지 않는다 .36) \n우리나라의 경우 의료기기에 해당하게 되면 사용목적과 인체에 미치는 잠재적 위해도에 따라 \n품목별로 4등급으로 분류하고37) 등급에 따라 요구되는 인허가절차가 개괄적으로 정해진다 .38) 1\n등급 의료기기는 대개 신고 대상이고 , 2등급 의료기기는 의료기기안전정보원의 인증을 받아야 \n하며, 3등급 및 4등급 의료기기는 식약처의 허가를 받아야 한다. 다만 이미 인허가를 받은 의료\n기기와 구조·원리·성능·사용목적 등이 본질적으로 동등하지 않은 의료기기의 경우 시판 전 단계\n에서 허가를 받기 위한 임상자료 평가를 거쳐야 한다.39)\n(2) 소프트웨어에 적합한 규제는 어떠해야 하는가?\n이처럼 미국의 규제당국은 일정한 의료목적의 소프트웨어를 의료기기로 보아 규제하기로 하\n였으나 ,", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 24, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "5c55a02df903eabbddc6bfd579f2cf6b", "text": "자료 평가를 거쳐야 한다.39)\n(2) 소프트웨어에 적합한 규제는 어떠해야 하는가?\n이처럼 미국의 규제당국은 일정한 의료목적의 소프트웨어를 의료기기로 보아 규제하기로 하\n였으나 , 기존의 하드웨어 중심의 전통적 규제방식이 소프트웨어 의료기기에는 적합하지 않다는 \n문제가 대두되었다 . 새로이 개발된 소프트웨어 의료기기에 기존의 시판전 허가(Premarket \nApproval, PMA) 절차를 그대로 적용하면 위험도가 낮은 소프트웨어 의료기기도 시장에 나오기 \n어려워 환자들이 혜택을 볼 수 없게 된다는 것이었다 . \n이러한 문제점을 인지한 미국 식품의약품안전청 (FDA)은 2017년 소프트웨어 의료기기에 대한 \n사전 인증(Pre-Cert) 프로그램을 시범적으로 실시하였다 .40) 이 프로그램은 개별 제품에 초점을 맞\n추기 보다는 품질 기준을 충족하는 기업을 사전인증 하겠다는 접근이다 . 소프트웨어의 설계, 유\n지·보수, 공급사설망 , 기업평판 등을 분석하여 사전인증을 받은 기업은 간소화된 절차를 거치도\n록 함으로써 더 적은 데이터를 제출하고도 제품을 일단 출시할 수 있도록 하되, 그 후에 시장에\n36)의료기기에 해당하는 소프트웨어는 가) 의료용 빅데이터를 기반으로 의료정보를 분석하여 얻은 임상정보 (예: \n종양 병변 크기·위치 등)를 이용하여 환자의 질병 유무, 상태 등에 대한 가능성 정도를 자동으로 진단·예측, \n모니터링하거나 치료하는 소프트웨어와 나) 의료용 빅데이터를 기반으로 의료영상 , 체외진단 기기로부터 나\n온 시그널 , 신호획득시스템 (심전계 , 뇌파계 등)에서 나오는 패턴 또는 시그널을 분석하여 진단", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 25, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "8bebffe58fa0a55574413b41ea19d7df", "text": " 소프트웨어와 나) 의료용 빅데이터를 기반으로 의료영상 , 체외진단 기기로부터 나\n온 시그널 , 신호획득시스템 (심전계 , 뇌파계 등)에서 나오는 패턴 또는 시그널을 분석하여 진단·치료에 필요\n한 임상정보를 제공하는 소프트웨어로 나뉜다 . 한편 의료기기에 해당하지 않는 의료용 소프트웨어로는 의료\n기관의 행정사무 (병실·재고관리 , 전자수속 등)를 지원하는 소프트웨어 , 운동·레저 및 일상적인 건강관리 목적\n의 소프트웨어 , 교육·연구 목적의 소프트웨어 , 질병 치료·진단 등과 관계 없는 의료기록 관리 목적의 소프트\n웨어, 의료인에게 환자의 건강정보 또는 진료정보를 정리 및 추적하는 툴을 제공하거나 의학정보에 쉽게 접\n근하도록 도움을 주는 소프트웨어 등이 있다. 건강보험심사평가원 , 혁신적 의료기술의 요양급여 여부 평가 \n가이드라인 -AI 기반 병리학 분야, 2020. \n37) 의료기기법 제3조, 동법 시행규칙 별표 1.\n38) 박정연 , “의료기기 진입규제의 변화: 공법적 정당화 논거와 규제 방향성 ”, 「법학논총」, 제46집(2020).\n39)의료기기법 시행규칙 제4조, 제9조. 이미 인허가를 받은 의료기기와 본질적으로 동등한지 여부는 의료기기\n의 특성에 따라 다르나 일반적으로는 기존 제품과 사용목적 및 작동원리가 같고 성능, 원재료 또는 사용방\n법 등이 동등한 의료기기를 본질적으로 동등한 의료기기로 판단한다 . 의료기기 허가·신고·심사 등에 관한 규\n정 별표 5, 별표 7. \n40) FDA, Guidance on Software as a Medical Device(SAMD): Clinical Evaluat", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 26, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "7052f38c235fdf58fbd9302f295e86e7", "text": "·심사 등에 관한 규\n정 별표 5, 별표 7. \n40) FDA, Guidance on Software as a Medical Device(SAMD): Clinical Evaluation\n\n비교사법 제29권 4호(통권 제99호)\n226서 실제 임상에서의 성능을 보고 제품을 검증한다는 ‘총 제품 수명주기 접근방법 (Total product \nlifecycle approach, TPLC approach)’ 을 취한 것이다 . 식품의약품안전청 (FDA)은 2017년 9월 100여개 \n업체의 신청을 받아 그 중 9개 회사를 선발하여 파일럿 프로그램에 참여시켰다 .41)\n한편 우리나라에서도 2019년 의료기기산업 육성 및 혁신의료기기 지원법을 제정하면서 , 미국\n의 사전 인증(Pre-Cert) 프로그램과 유사한 접근방법을 채택하였다고 알려져 있다. ‘기존의 의료\n기기에 비하여 기술집약도가 높고 혁신 속도가 빠른 분야의 첨단 기술의 적용이나 사용방법의 \n개선 등을 통하여 기존의 의료기기나 치료법에 비하여 안전성 , 유효성을 현저히 개선하였거나 \n개선할 것으로 예상되는 의료기기 ’를 혁신의료기기42)로 지정하여 단계별 심사43) 및 우선 심사를 \n허용함으로써 신속히 시판될 수 있도록 하는 것, 그리고 혁신의료기기소프트웨어 제조기업 인증\n제를 도입하여 허가시 일부 자료 제출을 면제하는 것이 그 주된 내용이다 .44)\n(3) 기계학습 의료기기 (Machine Learning-enabled Medical Devices, \nMLMD) 를 어떻게 규제할 것인가?\n인공지능 의료기기의 규제와 관련하여 남아있는 중요한 문제 중 하나는 ,", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 27, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "680d100dd1b6d553f1facb8184336310", "text": "hine Learning-enabled Medical Devices, \nMLMD) 를 어떻게 규제할 것인가?\n인공지능 의료기기의 규제와 관련하여 남아있는 중요한 문제 중 하나는 , 계속하여 적응하고 \n변화하는 알고리즘을 어떻게 규제할 것인가 하는 것이다 . 최근까지 허가나 인증을 받은 인공지\n능 의료기기는 모두 잠긴 알고리즘 (Locked algorithm), 즉 시판 후에 새로운 환경에 맞추어 변화\n하지 않는 제품들이었다 .45) 현재로서는 알고리즘이 사용환경에서 변화한다면 이러한 의료기기는 \n규제당국의 심사를 다시 받아야 할 것이고 , 제조업자로서는 갱신(update) 을 위한 심사에서 허가가 \n거절되거나 지연될 위험을 피하기 위해서라도 알고리즘을 갱신하지 않는 편을 택할 우려가 있\n다.46) 그러나 이러한 잠긴 알고리즘만 시판을 허용하게 되면  실시간으로 적응하고 기기 성능을 \n최적화하여 계속적으로 의료의 질을 향상시킬 수 있는 적응하는 (adaptive) 인공지능 기술을 활용\n할 수 있는 가능성은 아예 배제되는 결과가 될 것이다 . \n이에 미국 식품의약품안전청 (FDA)은 지속적으로 성능을 향상시키는 , 즉 실시간 학습하고 , 적\n41)Apple, Fitbit, Johnson & Johnson, Pear Therapeutics, Phosphorus, Roche, Samsung, Tidepool, 및 Verily가 파\n일럿 프로그램에 참여하였다 .\n42) 의료기기산업 육성 및 혁신의료기기 지원법 제2조 제4호. \n43)단계별 심사제도는 업체의 개발단계를 4단계로 나누어 각 단계별로 심사를 실시하는데 , ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 28, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "03332316d56df5904bd7e5cd5408d913", "text": "그램에 참여하였다 .\n42) 의료기기산업 육성 및 혁신의료기기 지원법 제2조 제4호. \n43)단계별 심사제도는 업체의 개발단계를 4단계로 나누어 각 단계별로 심사를 실시하는데 , 심사자는 단계별로 \n자료 제출일로부터 30일 내에 검토 결과를 통보하는 것을 원칙으로 하고, 단계별 심사가 완료되면 적합통지\n서를 발급하며 , 개발 완료 후 품목허가를 신청하면 신청 즉시 허가가 이루어진다 . 식품의약품안전처 , 첨단의\n료기기 단계별 허가심사 가이드라인 , 2016, 6면.\n44)의료기기산업 육성 및 혁신의료기기 지원법에서는 혁신의료기기 및 혁신소프트웨어에 대한 허가심사특례제\n도를 마련하여 단계별 심사제도 및 우선심사제도를 적용하도록 하고 있다. 박정연 , 위의 글, 187-188 면.\n45) Minssen, 5.\n46)Sara Gerke, Boris Babic, Theodoros Evgeniou & I. Glenn Cohen, The need for a system view to regulate \nartificial intelligence/machine learning-based software as a medical device, 53 NPJ Digital Medicine 1 (2020).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 227\n응하며 , 성능을 최적화시키는 인공지능 의료기기를 허용하기 위하여 앞서 살펴 본 총 제품 수명\n주기 접근방법 (Total product lifecycle approach) 이라는 큰 틀 안에서 , 시판 전에 미리 시판 후에 \n예", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 29, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "76b62ae4cae181f1d15550a1e9d25af3", "text": " 허용하기 위하여 앞서 살펴 본 총 제품 수명\n주기 접근방법 (Total product lifecycle approach) 이라는 큰 틀 안에서 , 시판 전에 미리 시판 후에 \n예상되는 수정사항과 재훈련 (retraining) 및 갱신(update) 방법론을 포함하는 “Predetermined Change \nControl Plan”을 제출하여 심사받도록 하고, 시판 후에도 지속적으로 모니터링하는 방안을 논의 \n중이다 .47) 한편 우리나라에서는 아직 기계학습 의료기기의 특성이 반영된 규제법규는 마련되지 \n않은 것으로 보인다 .48)\n4. 남아 있는 문제들\n지금까지 인공지능 의료기기의 허가 또는 인증 건수를 살펴보면 , 미국은 2020년 한 해에만 약 \n100건,49) 우리나라는 같은 해에 약 50건50)으로, 시장 규모를 감안할 때 우리나라가 인공지능 의\n료기기 시장에 상당히 적극적으로 참여하고 있는 것을 알 수 있다. 그러나 인공지능 의료기기가 \n허가 또는 인증을 받은 후에 우리나라 환자들이 실제로 그 혜택을 보기 위해서는 또 다른 절차, \n즉 신의료기술평가를 거쳐 국민건강보험법에 따른 요양급여 또는 비급여 항목으로 등재하는 절\n차를 거쳐야 한다.51) 특히 보험 수가 인정의 문제는 인공지능 의료기기가 실제 임상에 도입되는 \n데에 또 하나의 장애물로 인식되고 있다. 보험 수가를 인정받지 못하면 의료기관 또는 의사로서\n는 비싼 비용을 들여 인공지능 의료기기를 도입할 유인이 줄어들기 때문이다 . \n보건복지부와 건강보험심사평가원은 가장 개발이 활발한 AI 영상 및 병리, 3D 프린팅 분야에 \n대해 건강보험 적용에", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 30, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "cd6c595798051e5220b43c7c94e4b536", "text": " 들여 인공지능 의료기기를 도입할 유인이 줄어들기 때문이다 . \n보건복지부와 건강보험심사평가원은 가장 개발이 활발한 AI 영상 및 병리, 3D 프린팅 분야에 \n대해 건강보험 적용에 대한 예측가능성을 높이고 평가기간을 단축하고자 건강보험 등재 및 보상\n에 대한 가이드라인을 마련하였다 .52) 주요 골자는 환자의 치료에 도움이 되거나 비용절감이 입\n47)FDA, Proposed Regulatory framework for public comment for Modifications to AI/ML-Based Software as a \nMedical Device (SaMD); FDA, AI/ML-Based Software as a Medical Device Action Plan. FDA의 위 \ndiscussion paper와 잠긴(“locked”) 또는 변화하는 (“adaptive”) 알고리즘의 취급에 대한 논의로는 , Boris Babic, \nSara Gerke, Theodoros Evgeniou & I. Glenn Cohen, Algorithms on regulatory lockdown in medicine, 366 \nScience 1202 (2019). \n48)박정연 , 위의 글, 200면; 손승호 외 4인, “빅데이터 및 인공지능 기술 적용 의료기기의 허가심사 방안”, 「대\n한전자공학회 학술대회 논문집」(2018), 1732면.\n49)U.S. Food and Drug Administration,  Artificial Intelligence and Machine Learning (AI/ML)-Enabled Me", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 31, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "7104faa927ecb10d8ec2810c8f27716e", "text": ")U.S. Food and Drug Administration,  Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical  \nDevices , https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learni ng\n-aiml-enabled-medical-devices\n50)2021년 5월 현재 국내 시장에 출시된 인공지능 의료기기는 총 112개이다 . 식품의약품안전처 , 2022. 5. 12.자 \n보도자료 , 7면. \n51)박정연 , 위의 글, 183면. 신의료기술평가란 해당기기를 사용한 새로운 의료기술이 안전성과 유효성을 갖추었\n는지를 의료법 제53조에 의거하여 체계적 문헌고찰방법론을 토대로 신의료기술평가위원회 및 분야별 전문\n평가(소)위원회에서 심의하는 절차이다 . 위의 글.\n52)보건복지부 /건강보험심사평가원 , 혁신적의료기술의 요양급여여부 평가 가이드라인 -AI기반 의료기술 (영상의학\n분야) & 3D 프린팅 이용 의료기술 , 2019; 보건복지부 /건강보험심사평가원 , 혁신적의료기술의 요양급여여부 \n\n비교사법 제29권 4호(통권 제99호)\n228증된 경우에 별도 수가를 인정하자는 것이다 . 위 가이드라인에서는 AI 의료기술을 그 효과에 따\n라 4단계로 구분하여 , 진료 업무 효율 향상이 있거나 기존 행위와 유사한 수준의 진단능력만을 \n가진 경우에는 별도 보상하지 않고, 기존 행위 대비 현저하게 진단능력이 향상되", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 32, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "d62f0399e6912a942d8114f61d9be942", "text": " 따\n라 4단계로 구분하여 , 진료 업무 효율 향상이 있거나 기존 행위와 유사한 수준의 진단능력만을 \n가진 경우에는 별도 보상하지 않고, 기존 행위 대비 현저하게 진단능력이 향상되거나 , 새로운 진\n단적 가치를 창출하거나 , 또는 치료 효과성이 있는 경우, 또 이에 더해 비용 효과성을 입증한 경\n우라면 AI 의료기술의 경우 건강보험 적용을 고려해볼 만 하다고 밝히고 있다.53) 문제는 현재 \n우리나라에 나와 있는 인공지능 의료기기들이 이 요건을 만족시키기는 쉽지 않다는 것인데 , 아\n직까지 우리나라에서 별도로 수가를 인정받은 인공지능 의료기기는 없는 것으로 알려져 있다.\nⅢ. 인공지능 의료기기 오작동으로 인한 책임 분배\n1. 문제의 특수성\n이렇게 인공지능 기술을 활용한 의료기기가 여러 가지 장애물을 극복하고 임상 현장에서 활\n용된다 하더라도 항상 좋은 결과만 얻을 수 있는 것은 아닐 것이다 . 인공지능 의료기기가 편향\n성(bias)을 띠어 여성이나 노인 또는 소수인종에 관하여 저하된 성능을 보일 수 있다.54) 혹은 소\n프트웨어 오류가 발생하거나 보안에 문제가 발생하여 인공지능 의료기기가 오작동할 수도 있\n다.55) 이런 특별한 이유가 없더라도 , 확률적 예측을 하는 인공지능의 특성상  잘못된 결정을 내\n리는 경우는 언제든지 발생할 수 있다고 볼 수도 있다. 이처럼 인공지능 의료기기의 잘못된 권\n고로 환자의 건강이 침해되는 악결과가 발생하면 과연 누가 책임을 져야 할까?\n인공지능 자체에 법인격을 인정하고 있지 않은 현행 법제상 인공지능 의료기기를 사용한 의\n료인이 일차적인 책임의 주체로 고려될 수밖에 없다.5", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 33, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "37a3f9a5be7d541c1eaf6f6ea8d02bbd", "text": "발생하면 과연 누가 책임을 져야 할까?\n인공지능 자체에 법인격을 인정하고 있지 않은 현행 법제상 인공지능 의료기기를 사용한 의\n료인이 일차적인 책임의 주체로 고려될 수밖에 없다.56) 지금까지 인공지능 의료기기의 오작동으\n평가 가이드라인 -AI기반 의료기술 (병리학분야 ), 2020. \n53) 위의 글.\n54)인공지능 의료기기는 통상 각종 자원이 풍부한 대학병원에서 수집한 데이터를 활용하여 훈련되는 경우가 많\n은데, 같은 대학병원에서 해당 의료기기를 활용한다면 문제가 없겠지만 , 대학병원처럼 인적, 물적 자원이 풍\n부하지 않은 예컨대 지방의 작은 병원에서 인공지능 의료기기를 활용하는 경우 그 병원을 이용하는 환자들\n의 인구구성이 대학병원의 환자들의 구성과 다른 경우 성능이 저하되는 경우가 있을 수 있다. 또한 자원이 \n풍부한 대학병원과는 달리 자원이 부족한 의료환경에서는 추천된 치료방법을 적용하기 어려운 경우도 있을 \n수 있고 치료의 질이 떨어져 도움이 되지 않거나 오히려 해가 되는 경우도 있을 수 있다. W. Nicholson \nPrice II, 각주 23, 위의 글, 74~79면.\n55)물론, 의료과실로 문제될 수 있는 의사의 책임은 민사상 책임 외에도 형사상 책임과 행정상 책임이 있다. \n주호노 , 의사법학론 , 법문사 , 2017, 727~230 쪽. 다만, 이 글에서는 민사상 책임을 중심으로 논의를 한정한다 .\n56)인공지능에게 법인격을 인정하자는 주장은 1992년 Lawrence Solum에 의하여 제기된 바 있고 (Lawrence B. \nSolum, Legal Personhood for Artif", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 34, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "dd4d1b5cc4a9c13ea9716d8bcb391e11", "text": "에게 법인격을 인정하자는 주장은 1992년 Lawrence Solum에 의하여 제기된 바 있고 (Lawrence B. \nSolum, Legal Personhood for Artificial Intelligence, 70 N.C. L. Rev. 1231, 1252-53 (1992)), 2017년 자동화 \n로봇에게 법인으로서의 지위를 부여하여 손해를 배상하도록 하자는 주장이 담긴 유럽 의회의 보고서 (Comm. \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 229\n로 인한 책임에 관한 논의는 주로 의사의 의료과오책임을 위주로 이루어져 왔으나 , 의사뿐만 아\n니라 의료기관 , 인공지능 의료기기 제조업자 , 보험, 기타 배상제도를 포함하는 더 큰 틀에서 이 \n문제를 바라볼 필요가 있다. 책임 분배의 문제는 환자가 누구로부터 배상을 받을 수 있는가의 \n문제에 그치는 것이 아니라 , 인공지능 의료기기가 개발되고 임상에 도입될 수 있을 것인지 여부\n에도 직·간접적으로 영향을 미친다 .57) 따라서 기술 혁신을 저해하지 않으면서 인공지능 의료기\n기의 안전한 이용을 도모하는 균형잡힌 접근방법이 필요하다 .\n2. 의사의 책임\n(1) 의료과오책임\n의료인이 진단 및 치료상의 주의의무를 위반하여 환자의 생명, 신체, 건강을 침해한 경우에 \n지게 되는 책임을 의료과오책임이라고 한다.58) 의료과오책임은 의료계약의 불완전이행으로 인한 \n채무불이행책임 또는 불법행위책임으로 구성할 수 있으나 , 어느 쪽으로 구성하든 의사가 환자에 \n대한 치료에 있어서 최선의 주의의무를 다하지 않았다는 점을", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 35, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "4a45e535350218ea4eb32b33621e1afa", "text": "약의 불완전이행으로 인한 \n채무불이행책임 또는 불법행위책임으로 구성할 수 있으나 , 어느 쪽으로 구성하든 의사가 환자에 \n대한 치료에 있어서 최선의 주의의무를 다하지 않았다는 점을 환자 측에서 증명하여야 한다는 \n점에서는 차이가 없다.59) 판례에 따르면 책임의 전제가 되는 주의의무란 , 진찰, 치료 등의 의료\n행위와 관련하여 환자의 구체적 증상이나 상황에 따라 위험을 방지하기 위하여 요구되는 최선의 \n조치를 행하여야 할 의무이고 , 이는 의료행위를 할 당시 의료기관 등 임상의학 분야에서 실천되\non Legal Affairs, Eur. Union Parliament, Rep. with Recommendations to the Comm’n on Civ. L. Rules on \nRobotics, at 18 (2017)) 에 의하여 논란이 재점화되었다 . 그러나 이에 대하여는 위험을 야기한 자연인이나 법\n인에게 손해를 귀속시키면 충분하다는 강한 반대의견이 있었다 (Eur. Comm’n, Expert Group on Liability \nand New Technologies, Liability for Artificial Intelligence and Other Emerging Digital Technologies 38 \n(2019)). 최근까지 이어지고 있는 인공지능에 대한 법인격 부여에 관한 논란에 대하여는 , Benny Chan, \nApplying a Common Enterprise Theory of Liability to Clinical AI Systems, 47 Am. J. L. & Med. 351, 369 \n", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 36, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "2d63af42767faf25e0cd92a1d25a29ac", "text": "lying a Common Enterprise Theory of Liability to Clinical AI Systems, 47 Am. J. L. & Med. 351, 369 \n(2021) 참조. 의료영역에서 인공지능을 이용한 진단행위나 검사결과의 판독행위와 같이 인공지능의 판단에 \n독립성이 있다고 볼 수 있는 경우 인공지능에 법인격을 부여할 가능성이 있다고 보고, 이를 전제로 채무불\n이행책임과 불법행위책임을 분석한 글은, 백경희 /장연화 , 각주 13, 위의 글, 111~114 면 참조. \n57)George Maliha, Sara Gerke, I. Glenn Cohen & Ravi B. Parikh, Artificial Intelligence and Liability in \nMedicine: Balancing Safety and Innovation , 99 The Milbank Quarterly 629, 629-30 (2021).\n58)실무에서는 주로 불법행위책임으로 구성되는데 , 이는 환자 가족들이 위자료청구권을 실현하기 위한 것으로 \n이해된다 . 이상돈 /김나경 , 의료법강의 (제4판), 법문사 , 2020, 129-130 면. 그 외에도 배상의무자가 누구인지 , 지\n연손해금의 기산일 , 소멸시효기간 등에 있어서도 차이가 있다.\n59)백경희 /장연화 , “의료판례의 동향과 문제: 민사법적 쟁점과 전망을 중심으로 ”, 「한국의료법학회지 」, 제26권 \n제1호(2018), 226-227 면 (계약책임으로 구성하더라도 의사의 치료채무의 성질을 수단채무로 파악하는 우리 \n판례에 따르면 환자 측에서 의사가 최선", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 37, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "4359899247cf908f204c35a55356e3c2", "text": "법학회지 」, 제26권 \n제1호(2018), 226-227 면 (계약책임으로 구성하더라도 의사의 치료채무의 성질을 수단채무로 파악하는 우리 \n판례에 따르면 환자 측에서 의사가 최선의 주의의무를 다하지 않았다는 불완전이행을 증명할 수밖에 없음). \n청구원인을 채무불이행으로 구성하더라도 진료의무의 성격은 일반적으로 수단채무여서 나쁜 결과가 발생하\n였다는 사정만으로 곧바로 진료채무의 불완전이행이 있다고 볼 수 없다는 취지의 판례는 , 대법원 1988. 12. \n13. , 85다카1491 판결 등 참조.\n\n비교사법 제29권 4호(통권 제99호)\n230고 있는 의료행위의 수준을 기준으로 하며, 이처럼 요구되는 의료 수준은 , 통상의 의사에게 의료\n행위 당시 일반적으로 알려져 있고 또 시인되고 있는 이른바 의학상식을 뜻하므로 진료 환경 및 \n조건, 의료행위의 특수성 등을 고려하여 규범적인 수준으로 파악되어야한다고 한다.60) 판례가 요\n구하는 의료수준을 판단함에 있어 일부의 대학, 병원, 연구소 등에서만 알려져 있고 대부분의 의\n사에게 그 당시 널리 알려져 있지 않은 의학적 전문지식은 배제된다고 이해된다 .61)\n이러한 판단 기준은 미국에서도 크게 다르지 않다. 미국에서 의료과오책임은 의사가 의료 수\n준(standard of care)에서 벗어남으로 인하여 손해가 발생했을 것을 요건으로 하고,62) 이때 의료 \n수준(standard of care)은 동일 또는 유사한 상황에서 같은 분야의 평균적인 능력있는 의사가 따르\n는 일반적으로 승인되고 받아들여지는 관습과 절차를 따랐는지에 따라 결정된다 .63) 과거에는 지\n방의 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 38, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "bd1f910db211db9728caee3d00471637", "text": "e)은 동일 또는 유사한 상황에서 같은 분야의 평균적인 능력있는 의사가 따르\n는 일반적으로 승인되고 받아들여지는 관습과 절차를 따랐는지에 따라 결정된다 .63) 과거에는 지\n방의 소형 병의원의 의사들에게는 도시의 종합병원 의사들에게 요구되는 기준보다 낮은 기준을 \n요구해야 한다는 소위 locality rule이 존재하였으나 최근에는 일반의를 제외하고는 미국 전역의 \n전문의를 기준으로 판단하는 경향이다 .64)\n따라서 인공지능 의료기기의 치료 권고를 그대로 믿고 의료행위를 한 의사도 요구된 주의의\n무의 기준, 즉 의료수준에 미치지 못한 것으로 판단되면 책임을 질 수 있다.65) 의사가 인공지능 \n의료기기의 권고와는 별개로 , 요구되는 의료수준을 독립적으로 적용할 의무가 있다고 보는 것이\n다.66) Price 교수는 인공지능 의료기기의 권고를 따르거나 따르지 않음으로 인하여 환자에게 나\n쁜 결과가 발생한 경우의 의사의 책임 여부와 관련하여 여러 가지 경우의 수를 분석한 표를 제\n시하였는데 ,67) 아래의 표는 이를 간략하게 변형한 것이다 .\n환자에게 나쁜 결과가 발생한 경우를 전제로 하여 AI 권고의 의료수준 부합 여부(×2), 의사가 \n인공지능 의료기기의 권고를 따르는지 여부(×2)에 따라 경우의 수를 산정하면 총 네 가지 경우\n가 나온다 . 인공지능 의료기기의 권고가 맞는데 의사가 이에 따르지 않았거나 틀린 권고를 따른 \n경우에만 환자에게 나쁜 결과가 발생할 것이므로 AI 권고의 정확성 여부는 의사가 인공지능 의\n60)대법원 1999. 3. 26., 98다45379, 45386 판결. 이러한 의료과실의 개념은", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 39, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "0c8a388a5e40c333badc54cf9a042aac", "text": "자에게 나쁜 결과가 발생할 것이므로 AI 권고의 정확성 여부는 의사가 인공지능 의\n60)대법원 1999. 3. 26., 98다45379, 45386 판결. 이러한 의료과실의 개념은 계약책임이든 불법행위책임이든 동\n일하다 . 이상돈 /김나경 , 위의 책, 130면.\n61) 석희태 , “의료과실 판단기준에 관한 학설·판례의 동향”, 「의료법학 」, 창간호 (2000), 336쪽.\n62) Mahlia et al., 위의 글.\n63)A. Michael Froomkin, Ian Kerr & Joelle Pineau, When AIs Outperform Doctors: Confronting the Challenges of \na Tort-Induced Over-Reliance on Machine Learning, 61 Ariz. L. Rev. 33, 52-54 (2019).\n64) 위의 글.\n65)Mahlia et al., 위의 글; Maxwell J. Mehlman, Medical practice guidelines as malpractice safe harbors: illusion \nor deceit?, 40 JOURNAL OF LAW, MEDICINE & ETHICS 286,  (2012). 미국의 경우, 인공지능 의료기기의 \n사용과 관련한 판례가 아직 축적되지는 않았지만 , 유사한 사례에서 법원이 취한 태도에 비추어 볼 때, 인공\n지능 의료기기의 오류로 인한 책임을 의사가 지게 될 것으로 예상된다 . Ibid.\n66) Mahlia et al., 위의 글; Tesauro v Perrige, 650 A2d, 1079 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 40, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "66c6fc74ded666af3de27e91c61dd810", "text": "료기기의 오류로 인한 책임을 의사가 지게 될 것으로 예상된다 . Ibid.\n66) Mahlia et al., 위의 글; Tesauro v Perrige, 650 A2d, 1079 (Pa Super Ct 1994).\n67)W. Nicholson Price II, Potential LIability for Physicians Using Artificial Intelligence, 322 JAMA 1765, \n1765-66 (2019).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 231\n[표 1: 환자에게 나쁜 결과가 발생한 경우 의사의 책임]\nAI의 권고 의사의 선택 AI의 권고가 정확했는지 여부 책임 여부\n1\n의료수준에 부합따름 부정확 책임 없음\n2 따르지 않음 정확 책임 있음\n3\n의료수준을 일탈따름 부정확 책임 있음\n4 따르지 않음 정확 책임 없음\n료기기의 권고를 따르는지 여부에 연동되어 결정된다 . 이때 의사가 책임을 지는지 여부를 따져\n보면, 인공지능 의료기기의 권고가 의료수준에 부합하는데 따르지 않은 경우와 부합하지 않는데 \n따른 경우(2, 3)에는 책임이 있으나 , 그 반대의 경우(1, 4)에는 책임이 없다. Price 교수는 , 인공지\n능 의료기기의 도움을 받아 임상적 의사결정을 내리는 경우에도 현재 요구되는 의료수준에 따르\n는 한 책임을 지지 않기 때문에 , 의사로서는 인공지능 의료기기를 단지 확인하는 용도\n(confirmatory tool)로만 쓰는 것이 가장 안전한 셈이 된다고 한다.68) 결국, 현재의 책임 법리를 그\n대로 적용하면 의사는 책", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 41, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "9841a9dabf3981223da1df65e907bc66", "text": "공지능 의료기기를 단지 확인하는 용도\n(confirmatory tool)로만 쓰는 것이 가장 안전한 셈이 된다고 한다.68) 결국, 현재의 책임 법리를 그\n대로 적용하면 의사는 책임질 가능성을 피하기 위하여 인공지능 의료기기의 권고가 아니라 당시 \n의료수준에 맞추어 최종 결론을 내리게 될 것이므로 인공지능 의료기기의 잠재적 가치를 최소화\n하게 되는 것이다 .69) \n현재의 인공지능 의료기기의 발전 단계는 아직 그 성능이 인간을 뛰어넘거나 인간을 대체하\n는 것이 아니라 , 인간의 의사결정의 시간을 단축시키거나 실수를 줄여주는 보조적 기능에 머무\n르고 있다는 점을 고려하면 , 이러한 한계는 당장은 큰 문제라고 느껴지지는 않을 수 있다.70) 또\n한 과실 판단의 기준이 인공지능의 활용을 고려하여 변화할 가능성도 완전히 배제할 수는 없다. \n이처럼 의료수준을 벗어나는 인공지능의 추천을 따르는 경우 책임을 질 위험이 늘어나게 되므로 \n68) 위의 글, 1765.\n69)위의 글. 의료 수준(standards of care)의 변화가 의사의 행동의 변화에 큰 영향을 미친다는 연구결과는 , \nMichael Frakes, The Impact of Medical Liability Standards on Regional Variations in Physician Behavior: \nEvidence from the Adoption of National-Standard Rules, 103 American Economic Review 257 (2013).\n70)자율주행자동차의 자동화 수준 5단계별로 책임 분석을 달리하는 논의를 차용하", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 42, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e766ff6bc9d7e9b11c55015ee0208118", "text": "tandard Rules, 103 American Economic Review 257 (2013).\n70)자율주행자동차의 자동화 수준 5단계별로 책임 분석을 달리하는 논의를 차용하여 , 인공지능 영상의료판독에\n서도 발전 단계별로 책임 분배 여부를 판단하자는 논의도 있다(정창록 외 3인, “4차 산업혁명 시대의 기술 \n책임론에 대한 고찰: 자율주행자동차 기술 발전 5단계와 인공지능 영상의료판독 기술 발전 5단계를 중심으\n로”, 「한국의료법학회지 」, 제25권 제1호(2017), 155~172 면). 그러나 의사와 같이 면허를 받아 업무를 독점\n하는 인간전문직이 인공지능의 보조를 받아 의사결정을 하는 경우는 자율주행자동차의 소비자 지위에 놓인 \n운전자의 경우와는 차이가 있고, 의료계약에 따라 의사와 법적 관계를 맺는 환자의 경우는 자동차 사고 이\n전에는 아무런 특별 관계가 없는 제3자인 자동차 사고 피해자의 경우와 차이가 있다는 지적도 있다(설민수 , \n위의 글, 268-269 면). 물론 자율주행자동차의 경우 책임 논의와 인공지능 의료기기의 경우 책임 논의는 위와 \n같은 이유로 구별되어야 마땅할 것이나 , 인공지능 의료기기 기술의 발전 단계에 따라 의료행위에 관한 의사\n결정에서의 인공지능 의료기기의 역할 또는 의사의 역할이 달라지고 그 변화가 결국 책임관계에 영향을 미\n칠 수 있다는 점에서 기술 발전 단계별로 분석하는 접근방법은 여전히 의미가 있다.\n\n비교사법 제29권 4호(통권 제99호)\n232인공지능 의료기기의 잠재적 효용을 감소시키는 결과에 이를 것이라는 Price 교수의 주장을 검증\n하기 위하여 일반인 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 43, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "cdfa3ea9c33f7fdf0f0a8fff8b8c0b2c", "text": " 의미가 있다.\n\n비교사법 제29권 4호(통권 제99호)\n232인공지능 의료기기의 잠재적 효용을 감소시키는 결과에 이를 것이라는 Price 교수의 주장을 검증\n하기 위하여 일반인 2,000명을 대상으로 실시된 최근 한 연구에 따르면 , 의사가 의료수준을 벗어\n나는 인공지능의 추천(nonstandard recommendation) 을 받았고 , 그 인공지능의 추천이 실제로 그릇\n된(incorrect) 경우라도 잠재적 배심원은 의사가 이를 따른 것이 합리적이었다고 판단할 가능성이 \n높다고 한다.71) 비록 이 연구는 배심제를 전제로 미국에서 이루어진 연구이지만 , 일반인들이 의\n사가 인공지능의 추천이 의료수준을 벗어나는 경우에도 이를 따른 것을 합리적이라고 본 것은, \n적어도 일반인의 인식 속에서는 과실 판단의 기준이 인공지능을 고려하여 변화하고 있다고도 볼 \n수 있을 것이다 .72) \n향후 의사보다 뛰어난 성능을 가진 인공지능 의료기기가 널리 쓰이게 되면, 주의의무의 기준\n이 되는 의료수준 (standard of care)도 결국 그에 맞추어 상향될 것이다 .73) 인공지능 의료기기가 \n의사보다 더 뛰어난 실력을 갖추었을 뿐만 아니라 업무흐름에 방해가 되지 않고, 병원 측의 비\n용부담도 합리적인 선이라면 , 의료수준을 인공지능 의료기기의 성능에 맞추어 상향하지 않을 이\n유가 없을 것이다 . 이때는 의사들이 오히려 인공지능 의료기기가 내놓는 진단이나 치료방법을 \n따라야 할 주의의무를 지게 될 수도 있다.74)  인공지능 의료기기가 인간의 의사결정보다 일관되\n게 뛰어난 성능을 보인다면 , 이에 따르는 것이 평균적으", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 44, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "0e817d22d14e3c787f8f480874049e0a", "text": "놓는 진단이나 치료방법을 \n따라야 할 주의의무를 지게 될 수도 있다.74)  인공지능 의료기기가 인간의 의사결정보다 일관되\n게 뛰어난 성능을 보인다면 , 이에 따르는 것이 평균적으로 환자의 건강에 대한 침해를 줄이는 \n길이 될 것이기 때문이다 . \n그러나 인간 의사보다 뛰어난 성능을 가진 인공지능 의료기기가 널리 쓰이게 된다 하더라도 , \n의사가 인공지능 의료기기에 전적으로 의존하기 보다는 그 결정을 검증하고 필요시 무시\n(override) 하게 함으로써 , 인간과 기계가 한 팀을 이루어 서로를 보완하도록 하여야 한다.75) 아무\n리 인간 의사보다 뛰어난 성능을 갖춘 인공지능 의료기기가 개발된다고 하더라도 , 완벽한 성능\n을 갖추지 않은 이상 간혹 위양성 (false positive) 또는 위음성 (false negative) 의 권고를 제시하게 \n마련일 것이고 , 이러한 오류 중 일부는 인간 의사라면 하지 않았을 실수일 가능성이 있기 때문\n71)Kevin Tobia, Aileen Nielsen & Alexander Stremitzer, When Does Physician Use of AI Increase Liaiblity?, 62 \nJ. Nuclear Med. 17 (2021) (의료수준을 벗어나는 추천을 받은 경우, 응답자들은 의사가 이를 따르는 것\n(accept) 에 따르지 않는 것(reject) 에 비해 약간이나마 더 높은 합리성 점수(reasonablness rating)를 부여하였고 , \n이 차이는 통계적으로 유의하였음 ). 미국에서의 일반인의 인식에 대한 조사는 잠재적 배심원의 인식을 조사\n한다는", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 45, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "5b8007c9fecb7926b9770e3964e36b1a", "text": "리성 점수(reasonablness rating)를 부여하였고 , \n이 차이는 통계적으로 유의하였음 ). 미국에서의 일반인의 인식에 대한 조사는 잠재적 배심원의 인식을 조사\n한다는 측면에서 의미가 있고, 배심원의 판단에 이르지 않고 분쟁이 화해로 종결되는 경우에도 배심원의 판\n단이 어떠할 것이라는 예측에 근거하여 (in the shadow of law) 화해가 이루어질 가능성이 높다.\n72)W. Nicholson Price II, Sara Gerke & I. Glenn Cohen, How Much Can Potential Jurors Tell Us About \nLiability for Medical Artificial Intelligence?, 62 J. Nuclear Med. 15, 15 (2021).\n73) Froomkin et al., 위의 글.\n74)이러한 경우에는 과실을 피하기 위하여 의사가 ‘최신의 ’ 인공지능 의료기기를 도입하여야 할 의무가 있다고 \n보아야 한다는 주장은 , Philipp Hacker, Ralf Krestel, Stefan Grundmann & Felix Naumann, Explainable AI \nunder contract and tort law: legal incentives and technological challenges, 28 Artificial Intelligence and Law \n415, 421-423 (2020).\n75)다만 이러한 시점이 오면 전문의에 대한 수요가 줄고 수련 기회도 줄어들게 되어 인공지능 의료기기가 오\n작동하는 경우에 이를 감시하고 검증할 의사 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 46, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "7495e8ea2d650d3124d1c7f07d2afd41", "text": "421-423 (2020).\n75)다만 이러한 시점이 오면 전문의에 대한 수요가 줄고 수련 기회도 줄어들게 되어 인공지능 의료기기가 오\n작동하는 경우에 이를 감시하고 검증할 의사 인력도 부족해질 것이라는 예측으로는 , Froomkin et al., 위의 글.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 233\n이다. 따라서 의사가 언제나 인공지능의 결정을 그대로 따르는 것이 책임을 회피하는 방책이 되\n지 않도록 , 의사에게 인공지능의 결정이 잘못되었다는 의학적 근거가 있다면 이를 따르지 않을 \n주의의무를 부과하는 등 진단이나 치료방법을 결정함에 있어 의사의 실질적 참여를 의무화하여\n야 한다.76) 인공지능 의료기기의 결정에 대한 검증을 위한 구체적 기준 마련은 국회나 법원을 \n통해서도 이루어질 수 있을 것이나 , 과실 판단의 기준이 되는 의료수준이 통상의 의사를 기준으\n로 한다는 점을 고려하면 , 의사들이 주도하여 이러한 기준을 마련하는 것도 한 방법이 될 수 있\n을 것이다 .77)\n(2) 의사의 설명의무 위반책임\n의사는 의료과오책임을 지지 않는 경우라도 설명의무 위반으로 인한 책임을 질 여지가 있다. \n의사 측과 환자 측 사이에는 통상 의료정보의 보유량과 전문지식의 현격한 차이가 존재하므로 , \n환자의 자기결정권을 충분히 보장하기 위해 의사는 설명의무를 진다.78) 즉, 의사는 “환자가 스스\n로 자기결정권을 적절히 행사하여 의료행위의 시행 여부와 방법을 판단하여 선택할 수 있도록 , \n의료행위를 시행하기 전에 진료시술의 방법, 질병의 유무와 종류에 대한 진단", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 47, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "7b676e86b779dfbf47cf2f90d2532653", "text": "자가 스스\n로 자기결정권을 적절히 행사하여 의료행위의 시행 여부와 방법을 판단하여 선택할 수 있도록 , \n의료행위를 시행하기 전에 진료시술의 방법, 질병의 유무와 종류에 대한 진단 결과, 질병의 예후\n와 경과, 치료방법과 수단, 합병증과 부작용 등의 위험을 고지하여야 할 의무”가 있다.79) 인공지\n76)의사가 인공지능 의료기기와 다른 의견을 내는 경우 이에 대한 의학적 근거, 해당 의료기관의 특수한 상황 \n등에 대하여 주장, 입증이 가능하도록 증거를 남겨야 하고, 최종 결론에 대하여 협진 등 공동의사결정과정\n을 거치는 등 다시 한번 검증하는 것이 바람직하다는 견해는 , 배현아 , 위의 글. 의사는 인공지능 의료기기의 \n권고뿐만 아니라 의학적 경험을 고려하여 종합적인 판단을 내려야 한다는 견해로는 , Froomkin et al., 위의 글.  \n77)W. Nicholson Price II, Medical Malpractice and Blackbox Medicine, in Big Data, Health Law, and Bioethics \n(I. Glenn Cohen et al., eds.), Cambridge (2017) (구체적으로 위험도가 낮은 치료방법의 경우에는 별도의 검\n증이 필요하지 않지만 , 위험도가 높은 치료방법의 경우에는 검증 절차를 거치도록 하는 것이 바람직함 ). 의\n사 협회가 주의의무의 기준으로서의 의료수준에 영향을 미칠 수 있다는 점에 관하여는 , Michelle M. Mello, \nOf Swords and Shields: The Role of Clinical Practice Guideli", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 48, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "fdaf24b1cf0e2ef961371eead46f041a", "text": " 미칠 수 있다는 점에 관하여는 , Michelle M. Mello, \nOf Swords and Shields: The Role of Clinical Practice Guidelines in Medical Malpractice Litigation, 149U. \nPenn. L. Rev. 645 (2001) 참조. 인공지능 의료기기에 대한 평가 및 검증 방법에 대한 논의는 , Khalifa et al., \nDeveloping a framework for evidence-based grading and assessment of predictive tools for clinical decision \nsupport, 19 BMC Med Inform Decis Mak. 1 (2019); Wolff, Robert F., Karel GM Moons, Richard D. Riley, \nPenny F. Whiting, Marie Westwood, Gary S. Collins, Johannes B. Reitsma, Jos Kleijnen, and Sue Mallett. \n“PROBAST: a tool to assess the risk of bias and applicability of prediction model studies.” Annals of internal \nmedicine 170, no. 1 (2019): 51-58 참조.\n78)김재완 , “로봇수술로 인한 의료과오 민사책임에 있어 과실 판단의 문제”, 「아주법학 」, 제14권 제1호(2020), \n47면. 이러한 자기결정을 위한 설명 외에도 , 의료 개입이 이루어지는", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 49, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e1f7292d82326fd40e5e3580f220abf7", "text": "로봇수술로 인한 의료과오 민사책임에 있어 과실 판단의 문제”, 「아주법학 」, 제14권 제1호(2020), \n47면. 이러한 자기결정을 위한 설명 외에도 , 의료 개입이 이루어지는 중의 설명 및 요양방법지도와 같은 의\n료개입 후의 설명도 설명의무의 범주에 포함된다 . 이상돈 /김나경 , 위의 책, 139-140 면. 그러나 이 글에서는 \n인공지능 의료기기의 활용과 관련하여 의료적 개입 전의 자기결정을 위한 설명을 중심으로 논의한다 . 한편, \n판례는 설명의무의 근거에 관하여 , 환자는 헌법 제10조에서 규정한 개인의 인격권과 행복추구권에 의하여  \n생명과  신체의  기능을  어떻게  유지할  것인지에  대하여  스스로  결정하고  의료행위를  선택할  권리를 갖고(대법원 \n2017. 2. 15., 2014다230535 판결), 진료계약상의 의무 내지 침습 등에 의한 승낙을 얻기 위한 전제로서 의\n사의 설명의무가 필요하다고 (대법원 1994. 4. 15., 93다60935 판결) 설시한다 . \n\n비교사법 제29권 4호(통권 제99호)\n234능 의료기기의 사용과 관련한 설명의무 또는 인폼드 컨센트 (Informed Consent) 80)의 문제는 비교\n적 최근에서야 주목받기 시작한 이슈이다 .81) 임상에서 인공지능 의료기기를 도입하여 활용할 때, \n어떠한 경우에 설명의무가 있다고 보아야 하는지 , 어떠한 정보를 제공해야 하는지 , 즉 알고리즘\n의 설계(architecture) 나 인풋 데이터 , 편향(bias)의 가능성이나 데이터의 취약점까지 알려주어야 하\n는지 등에 관하여 해결되지 않은 문제들이 산재해 있다.", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 50, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "fca5a930695ccb51d9536ccbcb1b6967", "text": "알고리즘\n의 설계(architecture) 나 인풋 데이터 , 편향(bias)의 가능성이나 데이터의 취약점까지 알려주어야 하\n는지 등에 관하여 해결되지 않은 문제들이 산재해 있다. \n(가) 우리나라에서의 의사의 설명의무\n우리 판례는 일반적으로 “의사는 환자에게 수술 등 침습을 가하는 과정 및 그 후에 나쁜 결\n과 발생의 개연성이 있는 의료행위를 하는 경우 또는 사망 등의 중대한 결과 발생이 예측되는 \n의료행위를 하는 경우에 있어서 응급환자의 경우나 그밖에 특단의 사정이 없는 한 진료계약상의 \n의무 내지 침습 등에 대한 승낙을 얻기 위한 전제로서 당해 환자나 그 법정대리인에게 질병의 \n증상, 치료방법의 내용 및 필요성 , 발생이 예상되는 위험 등에 관하여 당시의 의료수준에 비추어 \n상당하다고 생각되는 사항을 설명하여 당해 환자가 그 필요성이나 위험성을 충분히 비교해 보고 \n그 의료행위를 받을 것인가의 여부를 선택할 수 있도록 할 의무가 있”다고 한다.82) \n우리나라의 판례는 두 단계로 설명의무 위반을 나누어 판단하는 것이 특징이다 .83) 즉, ㉠ 위\n자료만 청구하는 경우와 ㉡ 모든 손해를 청구하는 경우를 두 단계로 구분하여 , ㉠ 위자료만을 \n청구하는 경우에는 “의사의 설명결여 내지 부족으로 선택의 기회를 상실하였다는 사실만을 입증\n함으로써 족하고 , 설명을 받았더라면 사망 등의 결과는 생기지 않았을 것이라는 관계까지 입증\n할 필요는 없”으나, ㉡ 그 결과로 인한 모든 손해를 청구하는 경우에는 “그 중대한 결과와 의사\n의 설명의무위반 내지 승낙취득과정에서의 잘못과의 사이에 상당인과관계가 존재하여야 하며, \n", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 51, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "d3cbbb9bd1c4c61e7096e4b3804b8b1d", "text": "는 없”으나, ㉡ 그 결과로 인한 모든 손해를 청구하는 경우에는 “그 중대한 결과와 의사\n의 설명의무위반 내지 승낙취득과정에서의 잘못과의 사이에 상당인과관계가 존재하여야 하며, \n그 경우 의사의 설명의무의 위반은 환자의 자기결정권 내지 치료행위에 대한 선택의 기회를 보\n호하기 위한 점에 비추어 환자의 생명, 신체에 대한 의료적 침습과정에서 요구되는 의사의 주의\n의무위반과 동일시할 정도의 것이어야 한다”고 한다.84) 이와 같은 설명의무에 관한 법리는 판례\n79) 신현호 /백경희 , 의료분쟁 조정·소송 총론, 육법사 2011, 277-282 면.\n80)인폼드 컨센트 (Informed Consent) 에 대하여 자세한 내용은 최상회 /윤종민 , “인폼드 컨센트 (Informed Consent)\n의 법리구조 ”, 「법학연구 」, 제33집(2009), 112면 이하 참조.\n81)I. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?, 108 Geo. \nL.J. 1425(2020); Iñigo de Miguel, Begoña Sanz & Guillermo Lazcoz, Machine learning in the EU health care \ncontext: exploring the ethical, legal and social issues, 23 Info. Commc'n & Soc'y 1139 (2020); Maximilian \nKiener, Artificial intelligence in medicine", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 52, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "9eeddfb0960327eb669360be09c15b53", "text": "ssues, 23 Info. Commc'n & Soc'y 1139 (2020); Maximilian \nKiener, Artificial intelligence in medicine and the disclosure of risks, 36 AI & Soc. 705 (2021); Frank Ursin, \nCristian Temmermann, Marcin Orzechowski & Florian Steger, Diagnosing Diabetic Retinopathy With Artificial \nIntelligence: What Information Should Be Included to Ensure Ethical Informed Consent?, 8 Frontiers in \nMedicine 1, 5 (2021); H. Benjamin Harvey & Vrushab Gowda, Clinical applications of AI in MSK imaging: \na liability perspective, 51 Skeletal Radiology 235, 236 (2022).\n82) 대법원 1995. 1. 20., 94다3421 판결\n83)이동진, “의사의 위험설명의무 -법적 기능, 요건 및 위반에 대한 제재-”, 「의료법학 」, 제21권 제1호(2020), 12면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 235\n를 통하여 발전하여왔으나 2016년 의료법 개정을 통하여 명문의 규정을 두었다 .85) \n인공지능 의료기기를 활용하는 경우 언제, 어디까지 설명해야 하는지에 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 53, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "eeb5f29a34e314ae4dd382b65436ee1f", "text": "로|박혜진|\n 235\n를 통하여 발전하여왔으나 2016년 의료법 개정을 통하여 명문의 규정을 두었다 .85) \n인공지능 의료기기를 활용하는 경우 언제, 어디까지 설명해야 하는지에 관한 문제는 위험설명\n의 범위와 관련된다 . 판례는 위험설명의무 범위에 관하여 “질병의 증상, 치료방법의 내용 및 필\n요성, 발생이 예상되는 위험 등에 관하여 당시의 의료수준에 비추어 상당하다고 생각되는 사항\n을 설명하여 당해 환자가 그 필요성이나 위험성을 충분히 비교해 보고 그 의료행위를 받을 것인\n가의 여부를 선택할 수 있도록 하여야 ” 한다고 하고 있다.86) 또한 판례는 이러한 위험설명의무\n는 “그 의료행위에 따르는 후유증이나 부작용 등의 위험발생 가능성이 희소하다는 사정만으로 \n면제될 수 없으며 , 그 후유증이나 부작용이 치료행위에 전형적으로 발생하는 위험이거나 회복할 \n수 없는 중대한 것인 경우에는 발생가능성의 희소성에도 불구하고 설명의 대상”이 된다고 한\n다.87) 즉 발생확률이 극히 낮더라도 결과가 중하거나 전형적인 위험에 대하여는 널리 설명의무\n를 인정하고 있다. 이렇게 위자료만 배상을 명하는 경우에 판례는 자기 결정에 중요한 요소가 \n아니었을 수 있는 위험에 대한 설명을 하지 않은 경우에까지 널리 설명의무 위반을 인정하고 있\n는데, 이는 의료과오책임에 관한 증명 곤란을 구제하기 위한 차선책으로 이해되고 있다.88) \n84)대법원 1995. 1. 20., 94다3421 판결; 심병연 , “가. 의사가 환자에게 수술 등 침습을 가함에 있어 그 승낙을 \n얻기 위한 전제로서 부담하는 설명의무의 내용, 나. 설명의무위반과 손", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 54, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f043d6aa1af28656a15521d46cdb1b18", "text": "1. 20., 94다3421 판결; 심병연 , “가. 의사가 환자에게 수술 등 침습을 가함에 있어 그 승낙을 \n얻기 위한 전제로서 부담하는 설명의무의 내용, 나. 설명의무위반과 손해배상의 범위”, 「대법원판례해설 」, \n통권 제21호(1994), 174면 이하. 여기서 주의의무위반과 동일시할 정도의 설명의무위반이란 설명을 하였더라\n면 달리 결정하였을 개연성이 매우 큰 경우를 말한다 . 이동진 , 위의 글, 6면.\n85)의료법 제24조의2에서는 의료인이 사람의 생명 또는 신체에 중대한 위해를 발생하게 할 우려가 있는 수술, \n수혈, 전신마취를 하는 경우 환자에게 설명하고 서면 동의를 받아야 하는 사항을 정하고 , 이에 위반하는 경\n우 300만원 이하의 과태료에 처하도록 하고 있다(의료법 제92조 제1항 제1의3호 및 제1의4호).\n제24조의2(의료행위에 관한 설명) ① 의사ㆍ치과의사 또는 한의사는 사람의 생명 또는 신체에 중대한 위해\n를 발생하게 할 우려가 있는 수술, 수혈, 전신마취 (이하 이 조에서 “수술등 ”이라 한다)를 하는 경우 제2항\n에 따른 사항을 환자(환자가 의사결정능력이 없는 경우 환자의 법정대리인을 말한다 . 이하 이 조에서 같\n다)에게 설명하고 서면(전자문서를 포함한다 . 이하 이 조에서 같다)으로 그 동의를 받아야 한다. 다만, 설\n명 및 동의 절차로 인하여 수술등이 지체되면 환자의 생명이 위험하여지거나 심신상의 중대한 장애를 가\n져오는 경우에는 그러하지 아니하다 . \n② 제1항에 따라 환자에게 설명하고 동의를 받아야 하는 사항은 다음 각 호와 같다. \n1. 환자에게 발생하거나 발생 가능한", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 55, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f5829ad1be8a2533ecb9406d766cc51a", "text": "중대한 장애를 가\n져오는 경우에는 그러하지 아니하다 . \n② 제1항에 따라 환자에게 설명하고 동의를 받아야 하는 사항은 다음 각 호와 같다. \n1. 환자에게 발생하거나 발생 가능한 증상의 진단명  \n2. 수술등의 필요성 , 방법 및 내용 \n3. 환자에게 설명을 하는 의사, 치과의사 또는 한의사 및 수술등에 참여하는 주된 의사, 치과의사 또는 한의\n사의 성명 \n4. 수술등에 따라 전형적으로 발생이 예상되는 후유증 또는 부작용  \n5. 수술등 전후 환자가 준수하여야 할 사항\n86) 대법원 1995. 1. 20., 94다3421 판결.\n87) 대법원 2004. 10. 28., 2002다45185 판결.\n88) 박태신 , “의료소송에 있어서 설명의무의 기능”, 「연세법학연구 」, 제5권 1호(1998), 596면.\n\n비교사법 제29권 4호(통권 제99호)\n236(나) 미국에서의 의사의 설명의무 또는 인폼드 컨센트(informed consent)\n미국에서는 의사는 합리적인 의사 또는 합리적인 환자를 기준으로 중요한 (material) 정보를 공\n개하고 치료를 받을지 여부를 선택하도록 할 의무가 있다고 본다. 설명의무 위반으로 인한 책임\n은 일반 과실불법행위 (negligence) 책임으로 이해하되 , 설명의무 위반 이외에도 그 위험이 실현되\n었을 것(materialization of the risk)과 설명하였더라면 동의하지 않았을 것(decision causation) 을 요\n구하고 , 설명하지 아니한 위험이 실현되어 발생한 생명, 신체 침해 즉 전 손해에 대한 배상을 허\n용한다 . 미국의 각 주들은 인폼드 컨센트 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 56, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "c03431819c297bc9d54cee4dd57c547c", "text": "ision causation) 을 요\n구하고 , 설명하지 아니한 위험이 실현되어 발생한 생명, 신체 침해 즉 전 손해에 대한 배상을 허\n용한다 . 미국의 각 주들은 인폼드 컨센트 문제에 대한 접근방법에 관하여 환자 중심의 기준\n(patient-based standards) 과 의사 중심의 기준(physician-based standards) 로 나뉘어 있다. 환자 중심의 \n기준에 따르면 , 의사가 보기에 환자의 입장에 있는 합리적인 사람이라면 해당 치료를 받을 것인\n지 여부를 결정하는 데 중요하다고 여길 만 한 위험을 고지하여야 한다.89) 의사 중심의 기준에 \n따르면 , 합리적인 의료인이 동일한 또는 유사한 상황에서 고지하였을 내용을 설명하여야 한다.90)\n(다) 인공지능 의료기기를 활용한 경우 설명의무의 범위\n그렇다면 과연 인공지능 의료기기를 이용하여 진단에 도움을 받거나 치료 권고를 받는 경우\n에 이를 환자에게 설명해야 할까? 만약 그렇다면 어디까지 설명해야 할까? \n미국의 인폼드 컨센트 법리에 따르면 합리적인 의사 또는 합리적인 환자를 기준으로 중요한 \n정보에 해당하는지가 판단 기준이 될 것인데 , Cohen 교수는 지금까지 유사한 사례에서 적용된 \n판례 법리에 비추어 볼 때 환자에게 의료 인공지능을 사용하였음을 밝히지 않았다고 하여도 대\n부분의 경우에는 설명의무 위반이라고 볼 수 없을 것이라고 한다.91) 다만 1) 환자가 의사결정의 \n근거를 물었고 , 의료 인공지능이 실제로 의사결정을 주도하였거나 주된 역할을 하였음에도 의사\n가 그렇지 않은 것처럼 설명한 경우, 2) 인공지능 의료기기가 (예컨대 더", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 57, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e09f62eb444ca8bc58bd03b2cf7b6590", "text": "의사결정의 \n근거를 물었고 , 의료 인공지능이 실제로 의사결정을 주도하였거나 주된 역할을 하였음에도 의사\n가 그렇지 않은 것처럼 설명한 경우, 2) 인공지능 의료기기가 (예컨대 더 많은 비용이 들지만 환\n자의 건강을 더욱 증진시킬 수 있는 선택지를 제외하는 방식으로 ) 환자의 이익에 반하는 방식으\n로 활용된 경우, 그리고 3) (예컨대 알고리즘이 불투명하여 설명가능하지 않음으로 인하여 ) 의사\n가 의료인공지능이 옳은 판단을 내렸다고 믿을 만한 합리적 근거가 없는 경우에는 설명의무 위\n반이 인정될 여지가 있을 것이라고 한다.92) \n우리나라에서는 인공지능 의료기기 활용시 의사의 설명의무에 관하여 , 인공지능 기술로 인하\n여 정보의 비대칭이 강화되는 점과 새로운 기술의 임상 적용에 따른 위험성을 고려하여 기술 사\n89)Canterbury v. Spence 464 F.2d 772, 776 (D.C. Cir. 1972) (requiring disclosure “when a reasonable person, in \nwhat the physician knows or should know to be the patient’s positiion would be likely to attach significance \nto the risk or cluster of risks in deciding whether or not to forego the proposed therapy”).\n90)Natanson v. Kline 354 P.2d 670 (Kan. 1960) (mandating release of “the disclosure", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 58, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "158f1a5c13ae31ab3d21089a9572c0ac", "text": "posed therapy”).\n90)Natanson v. Kline 354 P.2d 670 (Kan. 1960) (mandating release of “the disclosures which a reasonable \nmedical practitioner would make under the same or similar circumstances”).\n91)I. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?, 108 Geo. L. \nJ. 1425 (2020).\n92) Ibid.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 237\n용 여부, 내용, 방식에 대한 정보를 제공하는 등 더욱 강화된 설명이 필요하고 이에 대한 명시적\n이고 유효한 동의 확보가 필요하다는 견해가 있다.93) 왓슨의 진단조력과 관련하여 진단행위의 \n중요성과 왓슨의 사용이 아직 생소한 현실이라는 점을 감안하여 왓슨의 진단조력의 개입여부 및 \n그 불안전성에 대하여 환자에게 설명할 필요가 있다는 견해도 있다.94) 위 견해들이 주장된 때에\n는 아직 우리나라 식약처의 정식 인증을 받은 인공지능 의료기기가 없을 때였다면 , 이제는 매년 \n수십가지의 인공지능 의료기기가 시장에 새롭게 쏟아져 나오고 있다. 그런데 인공지능 의료기기\n의 오작동으로 인한 책임을 설명의무위반으로 구성하는 경우, 기존에 의료과오책임에 대한 증명\n곤란을 구제하기 위하여 위자료 배상을 명하는 경우 설명의무 위반을 널", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 59, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "47da317cb661f28555a9aa4d18b92d13", "text": " 인공지능 의료기기\n의 오작동으로 인한 책임을 설명의무위반으로 구성하는 경우, 기존에 의료과오책임에 대한 증명\n곤란을 구제하기 위하여 위자료 배상을 명하는 경우 설명의무 위반을 널리 인정하던 우리나라의 \n기존의 판례의 태도가 그대로 유지된다면 , 그래서 자기결정에 중요한 요소가 아닌 부분까지 의\n사의 설명의무를 널리 인정하게 되면, 의사의 책임 범위가 과도하게 넓어질 우려가 있다. 자칫 \n의사들이 인공지능 의료기기를 사용하기를 꺼리게 되는 결과를 피하기 위해서는 의사의 인공지\n능 의료기기 사용시 설명의무 범위와 관련한 명확한 가이드라인이 마련되어 책임에 관한 불확실\n성을 해소하여야 할 것이다 . 이러한 가이드라인 마련을 위해서는 환자들이 해당 의료행위를 받\n을지 여부에 관한 의사결정을 하기 위해 어떤 정보를 필요로 하는지를 실증적으로 연구하고 , 그 \n후에 이를 바탕으로 현실적으로 문제가 될 법한 시나리오에 따른 설명의무 범위에 대한 가이드\n라인을 준비하는 것이 바람직할 것이다 . 나아가 이를 기초로 설명의무의 법리를 어떻게 적용하\n고 발전시켜나갈 것인지를 고민해야 한다. \n(3) 의료기관의 책임\n의사 개인보다는 상대적으로 자력이 충분한 의료기관을 상대로 책임을 묻는 것도 가능하다 . \n우선, 의료기관은 환자와 진료계약의 당사자이고 , 진료를 담당하는 개개의 의료인은 이행보조자\n에 불과하므로 , 의료사고와 같은 채무불이행이 발생하면 병원은 계약당사자로서 책임을 지게 된다.\n다음으로 , 의료기관은 피용자인 의사의 사무집행에 관련한 불법행위에 대하여 사용자로서 손\n해를 배상할 책임을 질 수 있다.95) 미국의 사", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 60, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "4394c872dfd141eb8aa2e39f206b6866", "text": "병원은 계약당사자로서 책임을 지게 된다.\n다음으로 , 의료기관은 피용자인 의사의 사무집행에 관련한 불법행위에 대하여 사용자로서 손\n해를 배상할 책임을 질 수 있다.95) 미국의 사용자책임 (respondeat superior ) 법리에 따르더라도 사\n용자는 피용자가 그 고용 범위 내의 행위를 하다가 저지른 불법행위에 대하여 책임을 진다.96) \n따라서 의료기관의 피용자인 의사가 인공지능 의료기기를 활용하여 환자에게 불법행위를 저질렀\n고, 그것이 피용자의 고용 범위 내의 행위였다면 , 환자는 의료기관에 대하여 사용자책임을 물을 \n여지가 있을 것이다 . 이와 같은 의료기관의 책임은 소위 대위책임에 해당한다 .\n93) 배현아 , 위의 글. 75-77면.\n94)장연화 /백경희 , “왓슨의 진단 조력에 대한 현행법상 형사책임에 관한 소고”, 「형사법의 신동향 」, 제55호\n(2017), 337-338 면. \n95) 민법 제756조 제1항 본문.\n96)Restatement (Third) of Agency § 2.04 (2006) (“employer is subject to liability for torts committed by \nemployees while acting within the scope of their employment”).\n\n비교사법 제29권 4호(통권 제99호)\n238뿐만 아니라 의료기관은 자기 고유의 책임으로서 손해배상책임을 부담할 수도 있다. 즉, 의사\n를 적절히 고용, 관리, 감독할 의무를 위반하였다거나 또는 적합한 시설과 설비를 유지할 의무를 \n위반하였다는 이유로 의료기관 스스로의 과실로 인", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 61, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "3750b2d32283b3ebbeedeca370b299b5", "text": "임을 부담할 수도 있다. 즉, 의사\n를 적절히 고용, 관리, 감독할 의무를 위반하였다거나 또는 적합한 시설과 설비를 유지할 의무를 \n위반하였다는 이유로 의료기관 스스로의 과실로 인한 불법행위 책임을 질 수도 있을 것이다 .97) \n의료기관으로서는 안전성과 유효성을 갖춘 인공지능 의료기기를 검증하여 도입하고 , 이를 제대\n로 활용하기 위하여 교육, 소프트웨어 업데이트 , 지원 및 보수 등을 게을리 하지 않아야 할 의무\n를 진다고 볼 수 있기 때문이다 .98) \n만일 인공지능 의료기기를 공작물로 볼 수 있는 경우라면 , 의료과오가 인공지능 의료기기의 \n설치 또는 보존상의 하자에 의하여 야기된 것인 경우 의료기관이 그 시설의 점유자 또는 소유자\n로서 무과실 손해배상책임을 질 여지가 있다.99) 여기서 말하는 공작물은 인공적으로 만들어진 \n설비를 말하는데 , 병원 건물과 실질적으로 일체로 되어 있는 각종 의료설비 , 예컨대 X선장치나 \nCT스캐너 등도 여기서 말하는 공작물이라고 할 수 있다.100) 그러나 인공지능 의료기기가 주로 \n그렇듯 소프트웨어의 형태를 띤다면 , 이는 공작물로 볼 수 없으므로 , 의료기관이 공작물의 점유\n자 또는 소유자로서 책임을 부담할 가능성은 없다.101)\n다만 인공지능 의료기기가 완전히 자동화 (fully autonomous) 되거나 , 인공지능 의료기기를 구매\n하고 사용하는 의료기관이나 의사보다는 이를 설계하고 제작한 제조업자의 관리 하에 있다고 볼 \n수 있게 되는 경우에는 인공지능 의료기기로 인하여 환자가 입은 손해에 관하여 의료기관에 그 \n과실에 근거한 책임(즉 의사의 과실을 전제로", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 62, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e2bcf53ab76465f4c07af948ae09f834", "text": " 제작한 제조업자의 관리 하에 있다고 볼 \n수 있게 되는 경우에는 인공지능 의료기기로 인하여 환자가 입은 손해에 관하여 의료기관에 그 \n과실에 근거한 책임(즉 의사의 과실을 전제로 한 사용자책임 또는 의료기관 고유의 과실에 기한 \n책임)을 묻는 것은 어려워질 수도 있다. 의료기관의 통제를 벗어나는 영역이라고 볼 수 있기 때\n문이다 .102) 그렇다면 이러한 경우에는 인공지능 의료기기 제조업자에게 책임을 물을 수 있을 것\n인가?\n97)Price II, 위의 글, 303, 304면. 미국의 의료기관의 직접 책임에 관한 법리는 , Mark A. Hall et al., Health \nCare Law and Ethics (Wolters Kluwer 2018) 445 참조. 우리나라에서도 병원은 조직편성상의 과실로 인한 불\n법행위 책임을 질 여지가 있다는 것은, 주호노 , 위의 책, 860~861 면 참조.\n98) Maliha, et al., 위의 글.\n99)민법은 공작물의 설치 또는 보존의 하자로 인하여 타인에게 손해를 가한 때에는 공작물점유자가 손해를 배\n상할 책임이 있다고 하고, (민법 제758조 제1항 본문), 점유자가 손해의 방지에 필요한 주의를 해태하지 아\n니한 때에는 그 소유자가 손해를 배상할 책임이 있다고 규정하고 있다(민법 제758조 제1항 단서).\n100) 주호노 , 위의 책, 859면.\n101) 이중기 /이재현 , 위의 글, 273면. \n102) Scott J. Schweikart, Who Will Be Liable for Medical Malpractice in the Future? How the ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 63, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "a7d568ee61e6bd70e2bcbe421ff02733", "text": " 273면. \n102) Scott J. Schweikart, Who Will Be Liable for Medical Malpractice in the Future? How the Use of Artificial \nIntelligence in Medicine Will Shape Medical Tort Law?, 22 Minnesota Journal of Law, Science & \nTechnology 1, 16 (2021).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 239\n4. 인공지능 의료기기 제조업자의 책임\n인공지능 의료기기의 제조업자에게 제조물책임을 묻는 데에는 여러 가지 난관들이 존재한다 . \n제조물책임을 묻기 위해서는 일단 제조물에 해당해야 하는데103) 소프트웨어를 제조물로 볼 수 \n있는지에 관하여 논란이 있다. 제조물책임법 제2조 제1호에 따르면 , “제조물 ”이란 제조되거나 가\n공된 동산을 말한다 .104) 동산은 부동산 이외의 물건을 의미하므로 ,105) 소프트웨어를 제조물로 볼 \n수 있는지의 문제는 소프트웨어를 물건, 즉 “유체물 전기 기타 관리할 수 있는 자연력 ”에 포함\n된다고 볼 수 있는지의 문제가 된다.106) 미국에서도 소프트웨어를 서비스 (service) 가 아닌 제조물\n(product) 로 볼 수 있는지에 대하여 마찬가지로 논란이 있고, 특히 SaMD(Software as a medical \ndevice) 와 같은 소프트웨어의 경우 제조물책임이 적용될 수 있는지 여부에 관하여는 아직 한국이\n나 미국 어디에서도 논란이 정리되지 않", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 64, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f3acd7e3e027ad940ee5e10126df459e", "text": "Software as a medical \ndevice) 와 같은 소프트웨어의 경우 제조물책임이 적용될 수 있는지 여부에 관하여는 아직 한국이\n나 미국 어디에서도 논란이 정리되지 않았다 .107)\n제조물 책임을 물으려면 결함이 인정되어야 하는데 , 우리 법은 제3차 미국 불법행위법 리스테\n이트먼트의 영향을 받아 제조상 결함, 설계상 결함, 표시상 결함의 세 유형을 구분하고 있다. 우\n선 제조상 결함은 원래 의도한 설계와 다르게 제조·가공된 결함을 말한다 . 가장 빈번하게 문제되\n는 유형의 결함은 아무래도 제조업자가 합리적인 대체설계를 채용하지 않아 안전성을 결여하게 \n된 경우에 해당하는 설계상 결함이 될 가능성이 높다. 그러나 인공지능 의료기기의 경우 그 작\n동방식을 이해하는 것도 쉽지 않은 점을 고려하면 , 합리적 대체설계의 존재를 증명한다는 것은 \n환자 입장에서 매우 어려울 것으로 보인다 . \n세 번째 결함 유형은 합리적인 설명, 지시, 경고 등 기타 표시를 했다면 당해 제조물에 의해 \n발생할 피해나 위험을 줄이거나 피할 수 있었을 경우에 인정되는 표시상 결함이다 . 이와 관련하\n여 제조업자는 인공지능 의료기기를 사용하기로 결정한 의사에게 적절한 지시, 설명, 경고를 한 \n것으로 의무를 다하였다고 주장할 수 있는데 , 이처럼 의료기기 제조업자에 대한 책임을 제한하\n는 것이 바로 ‘지식을 가진 중간자 이론(Learned intermediary doctrine)’ 이다.108) 의료기기의 제조\n103)제조물책임법 제3조(제조물 책임) ① 제조업자는 제조물의 결함으로 생명ㆍ신체 또는 재산에 손해(그 제조\n물에 대", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 65, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f2ab0a87187260f8af43e57125a9e569", "text": "diary doctrine)’ 이다.108) 의료기기의 제조\n103)제조물책임법 제3조(제조물 책임) ① 제조업자는 제조물의 결함으로 생명ㆍ신체 또는 재산에 손해(그 제조\n물에 대하여만 발생한 손해는 제외한다 )를 입은 자에게 그 손해를 배상하여야 한다.\n104) 제조물책임법 제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. \n1. “제조물 ”이란 제조되거나 가공된 동산(다른 동산이나 부동산의 일부를 구성하는 경우를 포함한다 )을 말\n한다.\n105) 민법 제99조 제2항.\n106) 민법 제98조(물건의 정의) 본법에서 물건이라 함은 유체물 및 전기 기타 관리할 수 있는 자연력을 말한다 .\n107)소프트웨어가 지금까지 제조물 (product) 보다는 서비스로 해석되고 있다는 점에 대하여는 , Barbara J. Evans \n& Frank Pasquale, Product Liability Suits for FDA-Regulated AI/ML Software in I. Glenn Cohen et al. (eds), \nThe Future of Medical Device Regulation: Innovation and Protection (Cambridge University Press, 2022); \nMichael D. Scott, Tort Liability for Vendors of Insecure Software: Has the Time Finally Come, 67 Md. L. \nRev. 425, 436-42 (2007); Frances E. Zollers et al., No More Soft Lan", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 66, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "0994f785759c222de59fe17db23c5d85", "text": "e Time Finally Come, 67 Md. L. \nRev. 425, 436-42 (2007); Frances E. Zollers et al., No More Soft Landings for Software: Liability for \nDefects in an Industry That Has Come of Age, 21, Santa Clara Computer & High Tech. L.J. 745 (2004). \n108) Timothy Hall, Reimagining the Learned Intermediary Rule for the New Pharmaceutical Marketplace, 35 Seton \n\n비교사법 제29권 4호(통권 제99호)\n240업자와 환자 사이에 의사가 끼어있기 때문에 의사를 최종 소비자로 보고, 제조업자로서는 의사\n에 대하여 지시·경고 의무를 다하는 것으로 충분하다는 것이다 . 따라서 의사에게 이러한 의무를 \n다한 경우 환자가 직접 의료기기 제조업자에 대한 제조물책임을 묻기는 어려워질 것이다 . \n마지막으로 연방제도를 택하고 있는 미국법에는 의료기기 제조업자에 대한 제조물책임을 묻\n는 데에 특유한 난관이 있다. 미연방헌법 제6조 2문의 연방법 우위 조항(the Supremacy Clause) 에\n서 파생한 연방법 우선적용이론 (Preemption doctrine) 이다.109) 1976년 미국 식품의약품화장품법\n(FDCA) 에 대한 의료기기 개정법 (Medical Devices Amendments) 에서 명시적으로 주법에서 연방법\n에서 정하는 조건과 다른 조건을 정하거나 추가", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 67, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "ec524e8eaae4d7c417071b661cd98471", "text": "약품화장품법\n(FDCA) 에 대한 의료기기 개정법 (Medical Devices Amendments) 에서 명시적으로 주법에서 연방법\n에서 정하는 조건과 다른 조건을 정하거나 추가하는 것을 금지한다고 정하여서 의료기기에 대한 \n연방법의 우위를 인정하였다 .110) 2008년 Riegel v. Medtronic, Inc에서 미국 대법원은 주법에 따른 \nPMA 절차를 거친 의료기기에 관한 불법행위 청구는 연방법 우선적용대상이어서 허용되지 않는\n다고 판단하였고 ,111) 한편 1996년 Medtronic, Inc. v. Lohr 판결에서는 PMA보다 완화된 501(k) 절\n차를 거친 의료기기에 관한 불법행위 주장은 연방법 우선적용대상이 되지 않는다고 판단한 바 \n있다.112) 이 두 사안에서 결론이 달라지게 된 결정적인 이유는 , PMA 절차를 거쳐 시판된 의료\n기기에 관한 불법행위 청구는 필연적으로 증거에 기반한 위험효용 분석(evidence-based risk-benefit \nanalysis) 의 반복을 초래하게 되는 반면, 완화된 501(k) 절차를 거쳐 시판된 의료기기의 경우에는 \n그렇지 않다는 데 있었다 .113)\n법조문과 일련의 판례들에 비추어 일반적으로 다음 세 가지의 경우 연방법 우선적용 원칙\n(preemption doctrine) 의 예외로 본다. 첫째, 가장 엄격한 시판전 허가절차인 PMA 절차를 거쳐 시\nHall L. Rev. (2005). 우리나라에서 ‘지식을 가진 중간자 이론(learned intermediary doctrine)’ 에 터잡아 의료\n기기 제조업자의 책임을 제한할 수 있을 것인", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 68, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "0a85dc32d1ce95bfaaeb222623def4f0", "text": "Rev. (2005). 우리나라에서 ‘지식을 가진 중간자 이론(learned intermediary doctrine)’ 에 터잡아 의료\n기기 제조업자의 책임을 제한할 수 있을 것인지에 대한 논의는 아직 활발하지 않으나 , 같은 논리가 적용될 \n수 있을 것으로 보인다 . \n109)인공지능 의료기기와 관련한 FDA의 규제와 제조업자의 책임 사이의 연방법 우선적용이론 (preemption \ndoctrine) 을 둘러싼 긴장관계에 관하여는 , Evans & Pasquale, 위의 글; Charlotte A. Tschider, Medical Device \nArtificial Intelligence: The New Tort Frontier, 46 BYU L. Rev. 1551 (2021). \n110) Medical Device Amendments of 1976, 21 U.S.C. § 360k(a)\n[N]o state . . . may establish or continue in effect with respect to a device intended\nfor human use any requirement —\n(1) which is different from, or in addition to, any requirement applicable under this chapter to the device, and\n(2) which relates to the safety or effectiveness of the device or to any other matter included in a requirement \napplicabl", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 69, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "72836b81767b65f2af12d81762e9a4f7", "text": "he safety or effectiveness of the device or to any other matter included in a requirement \napplicable to the device under this chapter.\n이와 같은 명시적 선점(explicit preemption) 외에도 주 입법을 적용하는 것이 연방법과 충돌하는 경우에는 \n해석을 통한 묵시적 선점(implicit preemption) 도 인정될 수 있다. 김장한 , “의료기기의 결함으로 인한 손해배\n상책임과 미국 연방법 우선 적용 이론에 관하여 ”, 의료법학 (제15권 제2호), 대한의료법학회 (2014), 74-75면.\n111) Riegel v. Medtronic, Inc., 552 U.S. 312 (2008).\n112) Medtronic, Inc. v. Lohr, 518 U.S. 470, 471 (1996).\n113) Robert L. Rabin & Alyssa J. Picard, Reassessing the Regulation of High-Risk Medical Device Cases, 68 \nDePaul L. Rev. 309, 322-23 (2019); Robert L. Rabin, Territorial Claims in the Domain of Accident Law: \nConflicting Conceptions of Tort Preemption, 74 Brook L. Rev. 987, 995 (2009).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 241\n", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 70, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "cea673882f28e07512aff40e224df52e", "text": "emption, 74 Brook L. Rev. 987, 995 (2009).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 241\n판된 의료기기의 경우에만 Riegel 판결이 적용되어 주법에 근거한 불법행위 청구에 대하여 연방\n법 우선적용의 항변(preemption defense) 을 행사할 수 있다. 둘째, “parallel actions” 즉 주법에 기한 \n불법행위 청구가 연방법 위반에 근거한 것인 때에는 새로운 조건을 추가하는 것이 아니기 때문\n에 연방법 우선적용 원칙의 적용을 받지 않는다 .114) 마지막 예외는 PMA 허가 이후에 새로운 중\n요한 증거가 나온 경우이다 .115) 규제 당국의 허가가 있은 후에 의료기기와 관련한 위험에 대한 \n새로운 증거가 발견되고 이에 기초한 불법행위 청구가 이루어진 경우라면 규제당국의 허가 당시\n에 이루어진 증거에 기반한 결정을 재검토할 필요가 없기 때문이다 .116)\n미국 법원은 지금까지 의사결정 보조 도구(decision support tool)로 여겨지는 의료 소프트웨어\n의 제조업자에게 제조물책임을 인정하는 데에 대체로 소극적이었다 .117) 우리나라에서도 아직 의\n료 소프트웨어 제조업자를 상대로 한 제조물책임 소송이 제기되었음은 알려진 바 없다.118) 다만, \n향후 인공지능 , 특히 그 작동방식을 이해하기 힘든 블랙박스와 같은 딥러닝 알고리즘이 의료에 \n널리 쓰이게 될 경우에 대비하여 인공지능 소프트웨어 의료기기에 대하여 제조물책임 법리의 확\n장, 적용이 필요한지에 대한 진지한 검토가 요청된다 . \n5. 보험 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 71, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "9744dfd2f7df79383cefb1cc6feb2b53", "text": "알고리즘이 의료에 \n널리 쓰이게 될 경우에 대비하여 인공지능 소프트웨어 의료기기에 대하여 제조물책임 법리의 확\n장, 적용이 필요한지에 대한 진지한 검토가 요청된다 . \n5. 보험 등을 통한 위험의 이전\n지금까지 인공지능 의료기기의 오작동으로 인한 의사, 의료기관 및 인공지능 의료기기 제조업\n자의 책임을 살펴보았는데 , 이들이 부담하는 위험을 분산하는 데에는 보험이 큰 역할을 할 수 \n있다. 인공지능 의료기기의 오작동으로 인한 위험의 분배에 보험의 역할도 빼놓을 수 없다. 의사\n나 의료기관은 의료배상책임보험에 가입함으로써 위험을 분산하려 할 수 있다. 한편 의료기기 \n제조업자 및 수입업자에 대하여는 최근 의료기기법 개정으로 책임보험 가입이 의무화되었다 .119) \n또한 위험의 분담 또는 이전은 보험 뿐만 아니라 계약을 통하여 , 예컨대 병원과 의사 사이에 \n혹은 의료기기 제조업체와 병원 사이에서 이루어질 수도 있다. 실제로 소프트웨어 제조업자들은 \n의료기관과의 이용허락계약 (license terms)을 통하여 책임을 이전하거나 면책을 요구하곤 한다.120) \n114) Riegel 재판의 다수의견은 명시적으로 이러한 경우 연방법상 요건에 추가하는 것이 아니라 평행한 (parallel) \n것이므로 연방법 우선적용 원칙의 적용을 받지 않는다고 명확히 하였다 . Riegel, 128 S. Ct. at 1011. \n115) Riegel, 128 S. Ct. at 1013.\n116) Rabin et al, 위의 글, 315-16.\n117) Price, W. Nicholson, II. Artificial Intelligen", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 72, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "808686333292f8313c9d8e5e417be76b", "text": " S. Ct. at 1013.\n116) Rabin et al, 위의 글, 315-16.\n117) Price, W. Nicholson, II. Artificial Intelligence in Health Care: Applications and Legal Implications, 14 The \nSciTech Lawyer 1, 11-12 (2017).\n118) 2010년까지 우리나라의 의료기기 결함으로 인한 대표적인 제조물책임소송은 2002년 제조물책임법 제정 전\n의 것들이었다 . 김상찬 , “의료기기의 결함과 제조물책임 ”, 「법학연구 」, 제39집(2010), 54-55면.\n119)의료기기법 제43조의6(보험가입 등) ① 대통령령으로 정하는 의료기기 제조업자 ㆍ수입업자는 의료기기를 \n사용하는 도중에 발생한 사망 또는 중대한 부작용 등으로 인하여 환자에게 발생한 피해를 배상하기 위하\n여 보험 또는 공제에 가입하여야 한다. ② 제1항에 따른 보험 또는 공제의 종류, 가입 대상, 보험금액 및 \n그 밖에 필요한 사항은 대통령령으로 정한다 . (시행일 : 2022. 7. 21.)\n\n비교사법 제29권 4호(통권 제99호)\n242예컨대 , 전자의무기록 (electronic health record, EHR) 시스템에 관한 공급계약에는 대체적 분쟁해결\n절차와 안전성 문제에 대한 비밀유지조항 (gag clause)과 함께 이러한 책임 이전에 관한 조항이 \n포함되어 있다.121) \n6. 공동사업책임 (common enterprise liability) 또는 기금 등을 통한 특별\n보상제도\n인공지능 의료기기의 특수성을 고려한 새로", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 73, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "c4fbbd7fe29d7a7c5cc5d105d2935d67", "text": "항이 \n포함되어 있다.121) \n6. 공동사업책임 (common enterprise liability) 또는 기금 등을 통한 특별\n보상제도\n인공지능 의료기기의 특수성을 고려한 새로운 배상체계를 구상하는 견해도 제시되고 있다. 인\n공지능의 불투명성 (opacity) 에도 불구하고 인공지능의 오작동으로 인한 책임을 묻기 위하여 과실\n을 입증하도록 요구하는 것은 부적절하다거나122) 인공지능 의료기기의 가소성 (plasticity) 이라는 \n특수한 성격을 고려하면 기존의 분쟁해결제도가 적절하지 않다는 지적이 있다.123) 이러한 이유\n로 인공지능 의료기기를 위한 새로운 배상체계를 구상하는 견해들이 제시되고 있다. 우선, 의사, \n인공지능 의료기기 제조업자 , 인공지능 의료기기를 채택한 의료기관이 불법행위로 인한 책임에 \n관하여 공동 사업 책임(common enterprise liability) 을 져야 한다는 견해가 있다.124) 이를 통해 인\n공지능 기술이 임상에 도입되면서 발생할 수 있는 책임의 공백을 줄이고 피해회복을 도모함과 \n아울러 관련된 이해관계자들이 주의의무를 다할 강력한 유인을 제공할 수 있다는 것이다 .125)\n다음으로 입법을 통하여 인공지능 의료기기로 인한 피해에 대하여 무과실 보상제도를 도입하\n고 의료기기회사로부터 부담금을 걷어 기금을 마련하여 이를 통해 피해를 구제하는 방안도 생각\n해 볼 수 있다. 예컨대 미국의 백신보상제도는 백신 제조업체들이 기금을 조성하여 백신 피해자\n들이 보상을 받을 수 있도록 함으로써 위험을 분산하는 제도이다 .126) 우리나라의 의약품에 관하\n여 식품의약품안전처 산하", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 74, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "f3803dca7facf162cb7b52ca6d662291", "text": "보상제도는 백신 제조업체들이 기금을 조성하여 백신 피해자\n들이 보상을 받을 수 있도록 함으로써 위험을 분산하는 제도이다 .126) 우리나라의 의약품에 관하\n여 식품의약품안전처 산하의 한국의약품안전관리원의 보상제도도 기금방식의 무과실보상제도 형\n식을 취하고 있다.127) 다만 이러한 제도를 채택할 경우 개별 제조업자들이 제품의 안전성을 향\n120) Evans 10.\n121) Jim Hawkins, Barbara Evans, Harlan Krumholz, Nontransparency in Electronic Health Record Systems, in \nTransparency in Health and Health Care in the United States 273-85 (Holly F. Lynch, I. Glenn Cohen, \nCarmel Shachar, Barbara J. Evans eds., 2019). \n122) Andrew D. Selbst, Negligence and AI’s human users, 100 B. U. L. Rev. 1315 (2020).\n123) Boris Babic et al,, 각주 46, 위의 글.\n124) Chan, 위의 글. 자율주행 자동차의 부품 제조업자들에게도 완성품 제조업자들과 함께 공동 사업 책임\n(common enterprise liability) 을 부과하여야 한다는 주장으로는 , David Vladeck, Machines Without Principals: \nLiability Rules and Artificial Intelligence, 89 Wash. L. R", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 75, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "ba4f8e2c311994202d3d2f005e4b5076", "text": "id Vladeck, Machines Without Principals: \nLiability Rules and Artificial Intelligence, 89 Wash. L. Rev. 117, 129 n.39 (2014).\n125) Chan, 위의 글.\n126) Sara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal challenges of artificial intelligence-driven \nhealthcare, in Artificial intelligence in Healthcare 314 (Adam Bohr & Kaveh Memarzadeh eds., 2020)..\n127)최철호 , “우리나라 의료기기 부작용에 따른 피해구제시스템 도입방안 연구”, 「한국의료법학회지 」, 제25권 \n제2호(2017), 52면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 243\n상시킬 인센티브가 줄어들 우려가 있다.128)\nⅣ. 마치며\n지금까지 우리나라와 미국을 중심으로 인공지능 의료기기와 관련한 규제법적 , 책임법적 이슈\n들을 조망하고 , 향후 연구와 토론이 필요한 문제들을 짚어보았다 . 우선 인공지능 의료기기의 규\n제와 관련하여 , 특히 기계학습 의료기기의 소위 업데이트 문제(update problem) 에 어떻게 대응할 \n것인지 및 인공지능 의료기기에 대한 보험수가 책정에 관한 문제가 당장 풀어야 할 숙제이다 . \n다음으로 , 인공지능 의료기기의 오작동으로 인한 책임 문제에 관하여 , 의사의 주의의무 기준 및 \n설", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 76, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "24cf31fc483b01a36b5751270a562dd8", "text": "능 의료기기에 대한 보험수가 책정에 관한 문제가 당장 풀어야 할 숙제이다 . \n다음으로 , 인공지능 의료기기의 오작동으로 인한 책임 문제에 관하여 , 의사의 주의의무 기준 및 \n설명의무 범위에 대한 구체적인 가이드라인 마련을 위한 이론적 , 실증적 연구가 필요하다 . 또한 \n인공지능 의료기기의 성능이 점점 향상될수록 소프트웨어 의료기기 제조업자의 제조물책임 인정\n과 관련한 논의 및 기금 등을 통한 특별보상제도 또는 특별한 분쟁해결절차의 마련의 필요성에 \n관한 논의가 더욱 필요하게 될 것으로 보인다 . 인공지능 의료기기와 관련하여 지금까지의 법적 \n논의를 정리하고 앞으로 더욱 연구와 논의가 필요한 쟁점을 소개하는 이 글이 이 분야의 활발한 \n연구와 이해관계자들의 토론을 촉발하는 계기가 되기를 기대해 본다. \n∙투  고  일:2022년 11월 03일\n∙심  사  일:2022년 11월 10일\n∙게재확정일 :2022년 11월 24일\n128) Gerke, et al., 위의 글.\n\n비교사법 제29권 4호(통권 제99호)\n244[참고문헌 ]\n[국내문헌 ]\n[단행본 ]\n이상돈 /김나경 , 의료법강의 (제4판), 법문사 , 2020, 129-130 면.\n신현호 /백경희 , 의료분쟁 조정·소송 총론, 육법사 , 2011, 277-282 면.\n[논문]\n김광수 , 인공지능 기반 과학기술과 국민의 권익구제 -자율주행차 , 드론 및 의료기기를 중심으로 -, 토지\n공법연구 , 제85집, 2019.\n김병관 /양석조 , 임상적 관점에서의 의료기기 관리제도 개선방안 연구, 과학기술법연구 , 제25집 제4호, \n2019.\n김상찬 , 의료기기", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 77, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "ab2cba803c163a8621dd38b868872714", "text": " 토지\n공법연구 , 제85집, 2019.\n김병관 /양석조 , 임상적 관점에서의 의료기기 관리제도 개선방안 연구, 과학기술법연구 , 제25집 제4호, \n2019.\n김상찬 , 의료기기의 결함과 제조물책임 , 법학연구 , 제39집, 2010.\n김재선 , 인공지능 의료기기 위험관리를 위한 규범론적 접근-인공지능 소프트웨어 규범화 논의를 중\n심으로 -, 공법연구 , 제46집 제2호, 2017.\n엄주희 /김소윤 , 인공지능 의료와 법제, 한국의료법학회지 , 제28권 제2호, 2020.\n김재완 , 로봇수술로 인한 의료과오 민사책임에 있어 과실 판단의 문제, 아주법학 , 제14권 제1호, \n2020.\n박정연 , 의료기기 진입규제의 변화: 공법적 정당화 논거와 규제 방향성 , 법학논총 , 제46집, 2020.\n박태신 , 의료소송에 있어서 설명의무의 기능, 연세법학연구 , 제5권 1호, 1998.\n배현아 , 보건의료법제 하에서 인공지능기술의 의료영역 도입의 의의와 법적 문제, 법조, 제724집, \n2017.\n백경희 /장경화 , 인공지능을 이용한 의료행위와 민사책임에 관한 고찰, 법조, 제724집, 2017.\n백경희 /장연화 , 의료판례의 동향과 문제: 민사법적 쟁점과 전망을 중심으로 , 한국의료법학회지 , 제26권 \n제1호, 2018.\n석희태 , 의료과실 판단기준에 관한 학설·판례의 동향, 의료법학 , 제1권 제1호, 2000.\n설민수 , 머신러닝 인공지능과 인간전문직의 협업의 의미와 법적 쟁점: 의사의 의료과실 책임을 사례로, \n저스티스 , 제163호, 2017.\n손승호 외 4인, 빅데이터 및 인공지능 기술 적용 의료기기의 ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 78, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "80b81798b4ecc94227e74b8cdc9afa9a", "text": "공지능과 인간전문직의 협업의 의미와 법적 쟁점: 의사의 의료과실 책임을 사례로, \n저스티스 , 제163호, 2017.\n손승호 외 4인, 빅데이터 및 인공지능 기술 적용 의료기기의 허가심사 방안, 대한전자공학회 학술대 회 \n논문집 , 2018.\n심병연 , 가. 의사가 환자에게 수술 등 침습을 가함에 있어 그 승낙을 얻기 위한 전제로서 부담하는 \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 245\n설명의무의 내용, 나. 설명의무위반과 손해배상의 범위, 대법원판례해설 , 통권 제21호, 1994.\n이동진 , 의사의 위험설명의무 -법적 기능, 요건 및 위반에 대한 제재-, 의료법학 , 제21권 제1호, 2020.\n이인영 , 보건의료에서의 인공지능 적용과 관련된 법적 과제에 대한 개관, 한국의료법학회지제 27권 제\n2호, 2019.\n이중기 /이재현 , 의료 AI에 대한 규제체제와 책임의 귀속-진단AI와 수술로봇을 중심으로 -, 홍익법학 , \n제21권 제4호, 2020.\n장연화 /백경희 , 왓슨의 진단 조력에 대한 현행법상 형사책임에 관한 소고, 형사법의 신동향 , 제55호, \n2017.\n정채연 , 의료 인공지능의 법적 수용을 위한 시론적 연구, 법학논총 , 제45권 제3호, 2021.\n최상회 /윤종민 , 인폼드 컨센트 (Informed Consent) 의 법리구조 , 법학연구 , 제33집, 2009.\n최철호 , 우리나라 의료기기 부작용에 따른 피해구제시스템 도입방안 연구, 한국의료법학회지 , 제25권 \n제2호, 2017.\n[기타자료 ]\n건강보험심사평가원 , 혁신적 의료", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 79, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "03432ffa1c3f411ccce2c24a4ed40ba3", "text": "009.\n최철호 , 우리나라 의료기기 부작용에 따른 피해구제시스템 도입방안 연구, 한국의료법학회지 , 제25권 \n제2호, 2017.\n[기타자료 ]\n건강보험심사평가원 , 혁신적 의료기술의 요양급여 여부 평가 가이드라인 -AI 기반 병리학 분야, 2020.\n보건복지부 /건강보험심사평가원 , 혁신적의료기술의 요양급여여부 평가 가이드라인 -AI기반 의료기술\n(병리학분야 ), 2020.\n보건복지부 /건강보험심사평가원 , 혁신적의료기술의 요양급여여부 평가 가이드라인 -AI기반 의료기술\n(영상의학분야 ) & 3D 프린팅 이용 의료기술 , 2019.\n식품의약품안전처 , 2022. 5. 12.자 보도자료 , 2022. \n식품의약품안전처 , 빅데이터 및 인공지능 (AI) 기술이 적용된 의료기기의 허가·심사 가이드라인 (민원\n인 안내서 ), 2017.\n식품의약품안전처 , 첨단의료기기 단계별 허가심사 가이드라인 , 2016.\n대법원 1988. 12. 13., 85다카1491 판결.\n대법원 1994. 4. 15., 93다60953 판결.\n대법원 1995. 1. 20., 94다3421 판결\n대법원 1999. 3. 26., 98다45379, 45386 판결.\n대법원 2004. 10. 28., 2002다45185 판결.\n대법원 2017. 2. 15., 2014다230535 판결.\n\n비교사법 제29권 4호(통권 제99호)\n246[외국문헌 ]\n[단행본 ]\nAmerican Law Institute, Restatement (Third) of Agency , American Law Institute Publishers, (2006).\nMark A", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 80, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "750f9b56b73d21de3e39752091ff33b2", "text": "can Law Institute, Restatement (Third) of Agency , American Law Institute Publishers, (2006).\nMark A. Hall et al., Health Care Law and Ethics , Wolters Kluwer, (2018).\n[논문]\nA. Michael Froomkin, Ian Kerr & Joelle Pineau, When AIs Outperform Doctors: Confronting the \nChallenges of a Tort-Induced Over-Reliance on Machine Learning , 61 Ariz. L. Rev. 33, 52-54 \n(2019)\nAndrew D. Selbst, Negligence and AI’s Human Users , 100 B.U. L. Rev. 1315 (2020)\nBarbara J. Evans & Frank Pasquale, Product Liability Suits for FDA-Regulated AI/ML Software  in I. \nGlenn Cohen et al. (eds), The Future of Medical Device Regulation: Innovation and \nProtection (Cambridge University Press, 2022).\nBenny Chan, Applying a Common Enterprise Theory of Liability to Clinical AI Systems , 47 Am. J. L. \n& Med. 351, 369 (2021).", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 81, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "bc9ae5cc563698726470d9ff5c2e0c6b", "text": "Common Enterprise Theory of Liability to Clinical AI Systems , 47 Am. J. L. \n& Med. 351, 369 (2021).\nBoris Babic et al., Beware Explanation from AI in Healthcare , 373 Science 284 (2021). \nBoris Babic, Sara Gerke, Theodoros Evgeniou & I. Glenn Cohen, Algorithms on regulatory lockdown \nin medicine , 366 Science 1202 (2019). \nCharlotte A. Tschider, Medical Device Art ㅜificial Intelligence: The New Tort Frontier , 46 BYU L. \nRev. 1551 (2021).\nDavid Vladeck, Machines Without Principals: Liability Rules and Artificial Intelligence , 89 Wash. L. \nRev. 117 (2014).\nFrances E. Zollers et al., No More Soft Landings for Software: Liability for Defects in an Industry \nThat Has Come of Age, 21, Santa Clara Computer & High Tech. L.J. 745 (2004).\nFrank Griffin, Artificial Intelligence and Liability in He", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 82, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "4def8d43e06346c0787744b28cb6f4d5", "text": "ra Computer & High Tech. L.J. 745 (2004).\nFrank Griffin, Artificial Intelligence and Liability in Health Care, 31 Health Matrix 65 (2021).\nFrank Ursin, Cristian Temmermann, Marcin Orzechowski & Florian Steger, Diagnosing Diabetic \nRetinopathy With Artificial Intelligence: What Information Should Be Included to Ensure \nEthical Informed Consent? , 8 Frontiers in Medicine 1, 5(2021)\nGeorge Maliha, Sara Gerke, I. Glenn Cohen & Ravi B. Parikh, Artificial Intelligence and Liability in \nMedicine: Balancing Safety and Innovation , 99 The Milbank Quarterly 629 (2021).\nH. Benjamin Harvey & Vrushab Gowda, Clinical applications of AI in MSK imaging: a liability \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 247\nperspective , 51 Skeletal Radiology 235 (2022).\nI. Glenn Cohen, Informed Consent and", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 83, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "d671abef4436103c974f8b024ca4eeac", "text": " 중심으로|박혜진|\n 247\nperspective , 51 Skeletal Radiology 235 (2022).\nI. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient? , 108 \nGeo. L.J. 1425 (2020)\nIñigo de Miguel, Begoña Sanz & Guillermo Lazcoz, Machine learning in the EU health care context: \nexploring the ethical, legal and social issues , 23 Info. Commc'n & Soc'y 1139 (2020).\nJim Hawkins, Barbara Evans, Harlan Krumholz, Nontransparency in Electronic Health Record Systems , \nin Transparency in Health and Health Care in the United States 273-85 (Holly F. Lynch, I. \nGlenn Cohen, Carmel Shachar & Barbara J. Evans eds., 2019). \nKevin Tobia, Aileen Nielsen & Alexander Stremitzer, When Does Physician Use of AI Increase \nLiaiblity? , 62 J. Nuclear Med. 17 (2021)\nKhalifa et al., Developing a framework f", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 84, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "2916c45f97f6e77e508931102a317955", "text": "e of AI Increase \nLiaiblity? , 62 J. Nuclear Med. 17 (2021)\nKhalifa et al., Developing a framework for evidence-based grading and assessment of predictive tools \nfor clinical decision support , 19 BMC Med Inform Decis Mak. 1 (2019).\nLatrice G. Landry, Heidi L. Rehm, Association of Racial/Ethnic Categories with the Ability of Genetic \nTests to Detect a Cause of Cardiomyopathy , 3 JAMA Cardiol 341 (2018)\nLawrence B. Solum, Legal Personhood for Artificial Intelligence , 70 N.C. L. Rev. 1231 (1992)\nMaximilian Kiener, Artificial intelligence in medicine and the disclosure of risks, 36 AI & Soc. 705 \n(2021)\nMaxwell J. Mehlman, Medical practice guidelines as malpractice safe harbors: illusion or deceit? , 40 \nJ. L., Med. & Ethics 286 (2012).\nMichael D. Scott, Tort Liability for Vendors of Insecur", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 85, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "8453c5c3998d5dcc41b87f28c52c1671", "text": "ceit? , 40 \nJ. L., Med. & Ethics 286 (2012).\nMichael D. Scott, Tort Liability for Vendors of Insecure Software: Has the Time Finally Come , 67 \nMd. L. Rev. 425 (2007); \nMichael Frakes, The Impact of Medical Liability Standards on Regional Variations in Physician \nBehavior: Evidence from the Adoption of National-Standard Rules , 103 Am. Econ. Rev. 257 \n(2013).\nMichelle M. Mello, Of Swords and Shields: The Role of Clinical Practice Guidelines in Medical \nMalpractice Litigation , 149 U. Penn. L. Rev. 645 (2001).\nPhilipp Hacker, Ralf Krestel, Stefan Grundmann & Felix Naumann, Explainable AI under contract \nand tort law: legal incentives and technological challenges , 28 Artificial Intelligence and Law \n415, 421-423 (2020).\nRobert F. Wolff et al., PROBAST: a tool to assess the risk of bias and ", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 86, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "573c02ea2b105e5b854aeded68713da8", "text": "nd Law \n415, 421-423 (2020).\nRobert F. Wolff et al., PROBAST: a tool to assess the risk of bias and applicability of prediction \nmodel studies , 170 Annals of internal medicine 51 (2019).\nRobert L. Rabin & Alyssa J. Picard, Reassessing the Regulation of High-Risk Medical Device Cases , \n68 DePaul L. Rev. 309 (2019).\nRobert L. Rabin, Territorial Claims in the Domain of Accident Law: Conflicting Conceptions of Tort \n\n비교사법 제29권 4호(통권 제99호)\n248Preemption , 74 Brook L. Rev. 987 (2009).\nSara Gerke, Boris Babic, Theodoros Evgeniou & I. Glenn Cohen, The need for a system view to \nregulate artificial intelligence/machine learning-based software as a medical device , 53 NPJ \nDigital Medicine 1 (2020).\nSara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal challenges of artificial intelligence-dri", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 87, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "59bc7b0eb6253fc2aedfd93a7ecf2a55", "text": "\nSara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal challenges of artificial intelligence-driven \nhealthcare, in Artificial intelligence in Healthcare 314 (Adam Bohr & Kaveh Memarzadeh eds., \n2020)..\nScott J. Schweikart, Who Will Be Liable for Medical Malpractice in the Future? How the Use of \nArtificial Intelligence in Medicine Will Shape Medical Tort Law? , 22 Minn. J. L., Sci. & \nTech. 1 (2021).\nTimo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory responses to \nmedical machine learning , 7 J. L.& Biosciences 1 (2020)\nTimothy Hall, Reimagining the Learned Intermediary Rule for the New Pharmaceutical Marketplace , \n35 Seton Hall L. Rev. (2005).\nW. Nicholson II Price, Black-Box Medicine , 28 Harv. J. L. & Tech. 419, 421 (2015); \nW. Nicholson Price II, Medi", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 88, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "e4d8cdab02deeec821bf5cfdf39127e9", "text": " II Price, Black-Box Medicine , 28 Harv. J. L. & Tech. 419, 421 (2015); \nW. Nicholson Price II, Medical AI and Contextual Bias, 33 Harv. J. L. & Tech. 65 (2019).\nW. Nicholson Price II, Medical Malpractice and Blackbox Medicine, in Big Data, Health Law, and \nBioethics (I. Glenn Cohen et al., eds., 2017).\nW. Nicholson Price II, Potential LIability for Physicians Using Artificial Intelligence , 322 JAMA \n1765 (2019).\nW. Nicholson Price II, Regulating Black-Box Medicine , 116 Mich. L. Rev. 421 (2017).\nW. Nicholson Price II, Sara Gerke & I. Glenn Cohen, How Much Can Potential Jurors Tell Us \nAbout Liability for Medical Artificial Intelligence? , 62 J. Nuclear Med. 15 (2021).\nW. Nicholson Price II. Artificial Intelligence in Health Care: Applications and Legal Implications , 14 \nThe SciTech Lawy", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 89, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "72d50ae1da205b5a1cceb773089ee2fd", "text": ". Artificial Intelligence in Health Care: Applications and Legal Implications , 14 \nThe SciTech Lawyer 1 (2017).\nZiad Obermeyer et al., Dissecting racial bias in an algorithm used to manage the health of \npopulations , 366 Science 447 (2019). \n[기타자료 ]\nMachine learning (AI) accurately predicts cardiac arrest risk, BMJ (May 17, 2021), \nhttps://www.bmj.com/company/newsroom/machine-learning-ai-accurately-predicts-cardiac-arrest-risk /.\nBoris Babic & Sara Gerke, Explaining Medical AI is Easier Said than Done , Stat news (Jul. 21,  \n2021),https://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-done.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 249\nComm. on Legal Affairs, Eur. Union Parliament, Rep. with Recommendations to the Comm’n on Civ. \nL. Rules on Robotics  (201", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 90, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "bb10ae15a7afadf227dc762111331425", "text": ", Eur. Union Parliament, Rep. with Recommendations to the Comm’n on Civ. \nL. Rules on Robotics  (2017), https://www.europarl.europa.eu/committees/en/report-with-recomme\nndations-to-the-commi/product-details/20170202CDT01121.\nEliza Strickland, Hospitals Roll out AI systems to Keep Patients From Dying of Sepsis , IEEE \nSpectrum (Oct. 19, 2018).\nEur. Comm’n, Directorate-General for Justice and Consumers, Liability for Artificial Intelligence and \nOther Emerging Digital Technologies  (2019), https://data.europa.eu/doi/10.2838/573689.\nIMDRF AIMD Working Group,  Machine Learning-enabled Medical Devices —A Subset of Artificial \nIntelligence-enabled Medical Devices: Key Terms and Definitions (2021).\nIMDRF SaMD Working Group, Software as a Medical Device\": Possible Framework for Risk \nCategorizatio", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 91, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "0588e076a7a68cecebd37746eaf23c9b", "text": "\nIMDRF SaMD Working Group, Software as a Medical Device\": Possible Framework for Risk \nCategorization and Corresponding Considerations  (2014).\nIMDRF SaMD Working Group, Software as a Medical Device (SaMD): Application of Quality \nManagement System  (2015).\nIMDRF SaMD Working Group, Software as a Medical Device (SaMD): Clinical Evaluation  (2017).\nIMDRF SaMD Working Group, Software as a Medical Device (SaMD): Key Definitions  (2013).\nJessica Hamzelou, AI system is better than human doctors at predicting breast cancer , New Scientist \n(Jan. 1, 2020). \nJessica Kent, One Third of Orgs Use A.I. in Med. Imaging , Health IT Analytics (Jan. 28, 2020), \nhttps://healthitanalytics.com/news/one-third-of-orgs-use-artificial-intelligence-in-medical-imaging.\nLiat Clark, Vinod Khosla: Machines will repla", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 92, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "dff886ab7d116e90477dead922ad62ac", "text": "f-orgs-use-artificial-intelligence-in-medical-imaging.\nLiat Clark, Vinod Khosla: Machines will replace 80 percent of doctors , Wired (Apr. 9, 2012), \nhttps://www.wired.co.uk/article/doctors-replaced-with-machines.\nU.S. Food and Drug Admin.,  Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a \nMedical Device Action Plan (2021), https://www.fda.gov/media/145022/download.\nU.S. Food and Drug Admin., General Wellness: Policy for Low Risk Devices, Guidance for Industry \nand Food and Drug Administration Staff (2019), https://www.fda.gov/media/90652/download.\nU.S. Food and Drug Admin., Guidance on Software as a Medical Device(SAMD): Clinical Evaluation  \n(2017), https://www.fda.gov/media/100714/download.\nU.S. Food and Drug Admin., How to Study and Market Your Device , https://www", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 93, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "cc5673b67b2e30792f4992b0baafeb46", "text": "/media/100714/download.\nU.S. Food and Drug Admin., How to Study and Market Your Device , https://www.fda.gov/medical-dev\nices/device-advice-comprehensive-regulatory-assistance/how-study-and-market-your-device.\nU.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to Artificial Intelligen ce\n/Machine Learning Based Software as a Medical Device (SaMD)  (2019), https://www.fda.gov/\nmedia/122535/download.\nU.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to AI/ML-Based Soft\nware as a Medical Device (SaMD) (2019), https://www.fda.gov/files/medical%20devices/publish ed\n\n비교사법 제29권 4호(통권 제99호)\n250/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf.\nU.S. Food and Drug Admin., Software as a Medical Device , https://www.fda.gov/medic", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 94, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "09abf5c53dabfdfb6206176971907cd4", "text": "ssion-Paper.pdf.\nU.S. Food and Drug Admin., Software as a Medical Device , https://www.fda.gov/medical-devices/digita l-\nhealth/software-medical-device-samd.\nU.S. Food and Drug Admin.,  Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical \nDevices , https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence -\nand-machine-learning-aiml-enabled-medical-devices.\nMedtronic, Inc. v. Lohr, 518 U.S. 470, 471 (1996).\nRiegel v. Medtronic, Inc., 552 U.S. 312 (2008).\nTesauro v Perrige , 650 A2d, 1079 (Pa Super Ct 1994).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 251\n[Abstract]\nLegal Challenges in Deploying Artificial Intelligence in Medicine: \nFocusing on the Evolution of Regulation and the Distribution of \nLiability\n129) Park, Hai Jin*\nTechnolo", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 95, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "53c9d81e645918328c69264876c6aef3", "text": "using on the Evolution of Regulation and the Distribution of \nLiability\n129) Park, Hai Jin*\nTechnological advances in artificial intelligence (AI) are transforming health care by assisting \nhealthcare providers and improving patient care. However, AI medical devices may err and adversely \naffect the physician’s decision-making, resulting in patient harm. Therefore, regulating AI medical \ndevices and allocating liability arising from algorithm inaccuracy is critical for patient safety and \ninnovation in clinical care. This paper provides an overview of the three evolutional stages in \nregulating AI medical devices and highlights the remaining issues for the regulatory agencies to be \naddressed. Moreover, this study considers multiple stakeholders beyond clinicians and alternative \npolicy op", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 96, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "684cf047be38cb76a8554d82f9499fe1", "text": "d. Moreover, this study considers multiple stakeholders beyond clinicians and alternative \npolicy options in its liability analysis and identifies questions that call for deeper investigation and \ndiscussion in the future. \n❙Key Words ❙\nmedical artificial intelligence, artificial intelligence medical device, medical device regulation, medical \nmalpractice, informed consent, duty to explain, product liability\n*Associate professor, Hanyang University Law School\n\n", "source": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "page": 97, "kind": "instructor", "title": "KCI_FI002904304(Medical AI regulation).pdf"}
{"id": "fc9069ecabdc6f743bb760246789c5be", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16340", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "6448a634052f3382299a14c2c641f5e0", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16295", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "5558282aed2a98801ed35a56d398e6b8", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16290", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "f900c5d03170b693a29243945837a8e2", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16292", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "d4371fb6b1944691e78b93ef7338621b", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16321", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "213a005ad25e6f4acea8dae0a6b548ac", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16328", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "6bf0d6b2cf6e2220a32d9f047a8f7801", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16334", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "3d649a145e4f876d425b4c0b499b3422", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16336", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "157bb6ea1d714e7d6e7cf71a9890d93b", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16350", "page": 1, "kind": "government", "title": "주요사업"}
{"id": "3659448ebb4c624248613f43256f9baa", "text": "주요사업\n사업공고 : 정보통신산업진흥원 검색어를 입력하세요. × 전체검색 열기 ENG 닫기 주요사업 전략분야 국가·산업 전반의 인공지능 확산 지역산업 혁신과 SW신산업 육성 선도 ICT산업 글로벌 경쟁력 확보 지원분야 사업화 해외진출 인프라 인력양성 법제도지원 정책연구 용어설명 알림마당 공지사항 사업공고 입찰공고 채용공고 시설개방 시설개방안내 시설사용신청 신청내역조회 공시송달 NIPA발간자료 법령 및 규정서식 우리원 관련 웹사이트 기업지원 정보제공 행정지원 ESG 열린경영 ESG 경영 ESG전략체계 ESG 경영공시 경영공시 윤리경영 추진체계 부패방지방침 부패임직원현황공개 윤리경영정책현황 신고물품 처리결과공개 인권경영 추진체계 인권헌장 인권경영 이행지침 안전경영 추진체계 안전경영방침 안전진단 결과공개 고객헌장 고객헌장 핵심서비스 이행표준 고객응대서비스 이행표준 핵심서비스 이행표준 실적 기업성장응답센터 기업성장응답센터 소개 기업민원보호헌장 국민참여 고객문의 갑질민원 청탁금지법위반/부패신고 예산낭비신고 복지보조금부정신고 공익신고 온라인행정심판 중소기업 옴부즈만 투명경영 감사계획 및 결과 범죄유형별 형사처분 임직원 현황 업무추진비 사용내역 수의계약현황 정관 및 주요규정 원규 제ㆍ개정 예고 기타정보공개 주요활동 환경경영체계 확립(E) 사회적책임경영 실현(S) 투명·소통경영 강화(G) NIPA소개 인사말 및 주요활동 인사말 원장 주요활동 설립목적 및 연혁 미션 및 비전 홍보센터 보도자료 기관장 기고 및 인터뷰 브로슈어 홍보영상 CI소개 조직도 및 직원안내 조직도 직원안내 지원시설 누리꿈스퀘어 부설기관 해외사무소 찾아오시는길 진천본원 진천본원평가장 서울평가장 누리꿈스퀘어 메타버스허브 정보공개 정보공개제도 정보공개제도란? 업무처리절차 정보공개방법 불복구제절차방법 공공기관 정보청구 정보목록 비공개세부기준 사업", "source": "https://www.nipa.kr/home/2-2/16302", "page": 1, "kind": "government", "title": "주요사업"}
